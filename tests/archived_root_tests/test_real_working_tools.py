#!/usr/bin/env python3
"""
Test the actual working tools we've already validated to find runtime breaking points
"""

import sys
sys.path.append('src')

import time
import json
import psutil
from datetime import datetime
from typing import List, Dict, Any

def test_working_tool_chain():
    """Use the same approach that worked in our evidence generation"""
    print("ðŸ”§ TESTING WORKING TOOL CHAIN (From Evidence)")
    print("=" * 80)
    
    try:
        # Use the exact same imports and setup that worked before
        from src.core.service_manager import ServiceManager
        from src.tools.phase1.t01_pdf_loader_unified import T01PDFLoaderUnified
        from src.tools.phase1.t15a_text_chunker_unified import T15ATextChunkerUnified  
        from src.tools.phase1.t23a_spacy_ner_unified import T23ASpacyNERUnified
        from src.tools.phase1.t27_relationship_extractor_unified import T27RelationshipExtractorUnified
        from src.tools.phase1.t31_entity_builder_unified import T31EntityBuilderUnified
        from src.tools.phase1.t34_edge_builder_unified import T34EdgeBuilderUnified
        from src.tools.phase1.t68_pagerank_calculator_unified import T68PageRankCalculatorUnified
        
        print("âœ… All imports successful")
        
        # Initialize service manager (like in our evidence tests)
        print("ðŸ”§ Initializing ServiceManager...")
        start_time = time.time()
        service_manager = ServiceManager()
        init_time = time.time() - start_time
        print(f"âœ… ServiceManager initialized in {init_time:.3f}s")
        
        # Test tool instantiation with service manager
        tools_to_test = [
            ("T01", T01PDFLoaderUnified),
            ("T15A", T15ATextChunkerUnified),
            ("T23A", T23ASpacyNERUnified),
            ("T27", T27RelationshipExtractorUnified),
            ("T31", T31EntityBuilderUnified),
            ("T34", T34EdgeBuilderUnified),
            ("T68", T68PageRankCalculatorUnified)
        ]
        
        instantiated_tools = []
        breaking_points = []
        
        for i, (tool_id, tool_class) in enumerate(tools_to_test):
            try:
                print(f"   ðŸ”§ Instantiating {tool_id}...")
                start_time = time.time()
                
                tool_instance = tool_class(service_manager)
                instantiation_time = time.time() - start_time
                
                instantiated_tools.append((tool_id, tool_instance))
                print(f"   âœ… {tool_id}: {instantiation_time:.3f}s")
                
            except Exception as e:
                error_msg = str(e)
                breaking_points.append({
                    "type": "instantiation_failure",
                    "tool": tool_id,
                    "position": i + 1,
                    "error": error_msg
                })
                print(f"   âŒ {tool_id}: FAILED - {error_msg}")
                break
        
        if len(instantiated_tools) == len(tools_to_test):
            print(f"âœ… All {len(tools_to_test)} tools instantiated successfully!")
            return test_execution_stress(instantiated_tools, service_manager)
        else:
            return {
                "instantiation_breaking_points": breaking_points,
                "successful_instantiations": len(instantiated_tools),
                "total_tools": len(tools_to_test)
            }
            
    except Exception as e:
        print(f"ðŸ’¥ FATAL ERROR: {e}")
        return {"fatal_error": str(e)}

def test_execution_stress(instantiated_tools: List, service_manager) -> Dict:
    """Test execution stress on instantiated tools"""
    print(f"\nðŸš€ TESTING EXECUTION STRESS ON {len(instantiated_tools)} TOOLS")
    print("=" * 60)
    
    results = {
        "stress_tests": [],
        "breaking_points": [],
        "max_successful_chain": 0
    }
    
    # Test 1: Single execution
    print("ðŸ”— Test 1: Single execution chain...")
    single_result = execute_tool_chain_once(instantiated_tools, 1)
    results["stress_tests"].append({"test": "single_execution", "result": single_result})
    
    if single_result["success"]:
        results["max_successful_chain"] = single_result["successful_tools"]
        print(f"âœ… Single execution: {single_result['successful_tools']} tools succeeded")
        
        # Test 2: Rapid repeated execution (stress test)
        print("\nðŸ”¥ Test 2: Rapid repeated execution (10x)...")
        rapid_results = []
        
        for i in range(10):
            rapid_result = execute_tool_chain_once(instantiated_tools, i + 1)
            rapid_results.append(rapid_result)
            
            if not rapid_result["success"]:
                results["breaking_points"].append({
                    "type": "execution_fatigue",
                    "iteration": i + 1,
                    "failed_at": rapid_result.get("failed_tool", "unknown")
                })
                print(f"ðŸ’¥ BREAKING POINT at iteration {i + 1}")
                break
            else:
                print(f"   âœ… Iteration {i + 1}: Success")
        
        results["stress_tests"].append({"test": "rapid_execution", "result": rapid_results})
        
        # Test 3: Memory pressure test
        print("\nðŸ§  Test 3: Memory pressure test...")
        memory_result = test_memory_pressure_with_tools(instantiated_tools)
        results["stress_tests"].append({"test": "memory_pressure", "result": memory_result})
        
    else:
        results["breaking_points"].append({
            "type": "execution_failure",
            "tool": single_result.get("failed_tool", "unknown"),
            "error": single_result.get("error", "unknown")
        })
        print(f"âŒ Single execution failed at {single_result.get('failed_tool', 'unknown')}")
    
    return results

def execute_tool_chain_once(instantiated_tools: List, iteration: int) -> Dict:
    """Execute the tool chain once and measure performance"""
    
    test_content = f"""
    KGAS Breaking Point Test - Iteration {iteration}
    
    Stanford University Artificial Intelligence Research Division
    Dr. Sarah Chen leads advanced machine learning research at Stanford University.
    The Natural Language Processing laboratory focuses on computational linguistics.
    
    MIT Computer Science and Artificial Intelligence Laboratory
    Professor John Smith at MIT works on robotics and autonomous systems research.
    The collaboration between Stanford and MIT produces breakthrough AI innovations.
    
    Test iteration: {iteration}
    Stress testing tool chain execution limits.
    """
    
    start_time = time.time()
    current_data = test_content
    
    for i, (tool_id, tool_instance) in enumerate(instantiated_tools):
        try:
            # Execute tool (simplified - just test if it runs)
            if tool_id == "T01":
                result = current_data  # Simulate PDF loading
            elif tool_id in ["T15A", "T23A", "T27", "T31", "T34"]:
                result = tool_instance.execute(current_data)
                current_data = getattr(result, 'data', result)
            elif tool_id == "T68":
                result = tool_instance.execute({})
                
        except Exception as e:
            return {
                "success": False,
                "failed_tool": tool_id,
                "failed_at_position": i + 1,
                "error": str(e),
                "execution_time": time.time() - start_time
            }
    
    return {
        "success": True,
        "successful_tools": len(instantiated_tools),
        "execution_time": time.time() - start_time,
        "iteration": iteration
    }

def test_memory_pressure_with_tools(instantiated_tools: List) -> Dict:
    """Test memory pressure by loading multiple spaCy models"""
    
    initial_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
    print(f"   ðŸ“Š Initial memory: {initial_memory:.1f} MB")
    
    memory_results = []
    spacy_tools = []
    
    # Find spaCy tools and stress test them
    for tool_id, tool_instance in instantiated_tools:
        if tool_id == "T23A":  # spaCy NER tool
            print(f"   ðŸ”„ Testing spaCy tool memory pressure...")
            
            try:
                # Execute spaCy tool multiple times
                for i in range(5):
                    tool_instance.execute(f"Memory pressure test {i + 1} with entities: Stanford University, MIT, Dr. Sarah Chen, Professor John Smith.")
                    
                    current_memory = psutil.Process().memory_info().rss / 1024 / 1024
                    memory_increase = current_memory - initial_memory
                    
                    memory_results.append({
                        "execution": i + 1,
                        "memory_mb": current_memory,
                        "increase_mb": memory_increase
                    })
                    
                    print(f"      Execution {i + 1}: {current_memory:.1f} MB (+{memory_increase:.1f} MB)")
                    
                    if memory_increase > 200:  # 200MB threshold
                        print(f"   âš ï¸ Memory threshold reached: {memory_increase:.1f} MB")
                        break
                
                return {
                    "initial_memory_mb": initial_memory,
                    "memory_results": memory_results,
                    "max_memory_increase": max([r["increase_mb"] for r in memory_results]),
                    "breaking_point": any(r["increase_mb"] > 200 for r in memory_results)
                }
                
            except Exception as e:
                return {
                    "error": str(e),
                    "initial_memory_mb": initial_memory
                }
    
    return {"no_spacy_tools_found": True}

def main():
    """Main breaking point analysis"""
    print("ðŸ’¥ REAL RUNTIME BREAKING POINT ANALYSIS")
    print("=" * 80)
    print("Testing actual runtime limits with working tools")
    print("=" * 80)
    
    results = test_working_tool_chain()
    
    # Save results
    results_file = f"WORKING_TOOLS_SUMMARY_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    final_results = {
        "test_type": "working_tools_runtime_analysis",
        "timestamp": datetime.now().isoformat(),
        "results": results
    }
    
    with open(results_file, 'w') as f:
        json.dump(final_results, f, indent=2)
    
    print(f"\n" + "=" * 80)
    print("ðŸŽ¯ RUNTIME BREAKING POINT SUMMARY")
    print("=" * 80)
    
    if "fatal_error" in results:
        print(f"ðŸ’¥ FATAL ERROR: {results['fatal_error']}")
    elif "instantiation_breaking_points" in results:
        print(f"ðŸ”§ INSTANTIATION FAILURE: {results['successful_instantiations']}/{results['total_tools']} tools")
        for bp in results["instantiation_breaking_points"]:
            print(f"   â€¢ {bp['tool']}: {bp['error']}")
    elif "breaking_points" in results:
        bp_count = len(results["breaking_points"])
        max_chain = results.get("max_successful_chain", 0)
        print(f"âš¡ RUNTIME BREAKING POINTS: {bp_count} found")
        print(f"ðŸ”— MAX SUCCESSFUL CHAIN: {max_chain} tools")
        
        for bp in results["breaking_points"]:
            print(f"   â€¢ {bp['type']}: {bp}")
    else:
        print("âœ… NO BREAKING POINTS FOUND - System performed within limits")
    
    print(f"\nðŸ“„ Full results: {results_file}")
    
    return final_results

if __name__ == "__main__":
    results = main()