#!/usr/bin/env python3
"""
KGAS System Monitoring Test - Phase 9.2 (Fixed Version)

Fixed tests for system monitoring capabilities with proper timing and expectations.
"""

import os
import sys
import time
import tempfile
import json
import threading
from pathlib import Path
from typing import Dict, Any, List
from datetime import datetime, timedelta

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from src.monitoring.system_monitor import (
    KGASSystemMonitor, HealthStatus, MetricType, HealthCheck, Metric,
    get_system_monitor, start_system_monitoring
)


def test_metrics_collection_fixed() -> bool:
    """Test metrics collection functionality (fixed)"""
    try:
        monitor = KGASSystemMonitor()
        
        # Test manual metric recording
        monitor._record_metric(
            "test_counter",
            42.0,
            MetricType.COUNTER,
            {"component": "test", "environment": "testing"},
            "Test counter metric"
        )
        
        # Verify metrics were recorded
        assert len(monitor.metrics) >= 1
        
        # Find specific metric
        counter_metric = next((m for m in monitor.metrics if m.name == "test_counter"), None)
        assert counter_metric is not None
        assert counter_metric.value == 42.0
        assert counter_metric.metric_type == MetricType.COUNTER
        assert counter_metric.tags["component"] == "test"
        assert counter_metric.description == "Test counter metric"
        
        # Test metrics retrieval
        all_metrics = monitor.get_metrics()
        assert len(all_metrics) >= 1
        
        # Test filtering by metric name
        counter_metrics = monitor.get_metrics("test_counter")
        assert len(counter_metrics) >= 1
        assert counter_metrics[0]["name"] == "test_counter"
        
        # Test filtering by time range (should include recent metrics)
        recent_metrics = monitor.get_metrics(time_range_hours=1)
        assert len(recent_metrics) >= 1
        
        return True
        
    except Exception as e:
        print(f"Metrics collection test failed: {e}")
        return False


def test_monitoring_thread_fixed() -> bool:
    """Test continuous monitoring thread (fixed)"""
    try:
        # Use short interval for testing
        config = {'check_interval': 0.5}  # 0.5 second interval
        monitor = KGASSystemMonitor(config)
        
        # Register a test component
        check_call_count = 0
        def test_component():
            nonlocal check_call_count
            check_call_count += 1
            return {'status': 'healthy', 'message': f'Test component OK {check_call_count}'}
        
        monitor.register_component("thread_test_component", test_component)
        
        # Start monitoring
        monitor.start_monitoring()
        
        # Wait for multiple monitoring cycles
        time.sleep(2.5)  # Should complete at least 4-5 cycles
        
        # Stop monitoring
        monitor.stop_monitoring()
        
        # Verify monitoring occurred (be more flexible with expectations)
        print(f"Health checks performed: {len(monitor.health_checks)}")
        print(f"Metrics collected: {len(monitor.metrics)}")
        print(f"Component check calls: {check_call_count}")
        
        # More flexible assertions
        assert len(monitor.health_checks) >= 2, f"Expected at least 2 health checks, got {len(monitor.health_checks)}"
        assert len(monitor.metrics) > 0, f"Expected some metrics, got {len(monitor.metrics)}"
        assert check_call_count >= 2, f"Expected at least 2 component checks, got {check_call_count}"
        
        # Verify component was checked multiple times
        component_checks = [hc for hc in monitor.health_checks if hc.component == "thread_test_component"]
        assert len(component_checks) >= 2, f"Expected at least 2 component checks, got {len(component_checks)}"
        
        # Verify we have some system metrics (more flexible)
        system_metrics = [m for m in monitor.metrics if m.tags.get("type") == "system"]
        assert len(system_metrics) > 0, f"Expected some system metrics, got {len(system_metrics)}"
        
        return True
        
    except Exception as e:
        print(f"Monitoring thread test failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        # Ensure monitoring is stopped
        try:
            monitor.stop_monitoring()
        except:
            pass


def run_comprehensive_test() -> bool:
    """Run all monitoring tests"""
    print("=" * 70)
    print("KGAS SYSTEM MONITORING COMPREHENSIVE TEST SUITE (FIXED)")
    print("=" * 70)
    
    tests = [
        ("Monitoring Initialization", test_monitor_initialization),
        ("Component Registration", test_component_registration), 
        ("Health Checks", test_health_checks),
        ("Metrics Collection (Fixed)", test_metrics_collection_fixed),
        ("Alert Generation", test_alert_generation),
        ("System Metrics", test_system_metrics),
        ("Monitoring Thread (Fixed)", test_monitoring_thread_fixed),
        ("Performance Tracking", test_performance_tracking),
        ("Monitoring Reports", test_monitoring_reports),
        ("Dashboard Data", test_dashboard_data)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        try:
            print(f"\nRunning {test_name}...")
            result = test_func()
            status = "‚úÖ" if result else "‚ùå"
            print(f"{status} {test_name}: {'PASSED' if result else 'FAILED'}")
            if result:
                passed += 1
        except Exception as e:
            print(f"‚ùå {test_name}: FAILED with exception: {e}")
    
    print(f"\n" + "=" * 70)
    print(f"TEST SUMMARY: {passed}/{total} tests passed")
    print("=" * 70)
    
    return passed == total


def test_monitor_initialization() -> bool:
    """Test system monitor initialization"""
    try:
        monitor = KGASSystemMonitor()
        assert monitor.monitoring_enabled == True
        assert monitor.check_interval == 30
        return True
    except Exception as e:
        print(f"Monitor initialization failed: {e}")
        return False


def test_component_registration() -> bool:
    """Test component registration"""
    try:
        monitor = KGASSystemMonitor()
        
        def test_health_check():
            return {'status': 'healthy', 'message': 'Component is working'}
        
        monitor.register_component("test_component", test_health_check, "Test component")
        assert "test_component" in monitor.components
        return True
    except Exception as e:
        print(f"Component registration failed: {e}")
        return False


def test_health_checks() -> bool:
    """Test health check functionality"""
    try:
        monitor = KGASSystemMonitor()
        
        def healthy_component():
            return {'status': 'healthy', 'message': 'All good'}
        
        def unhealthy_component():
            return {'status': 'unhealthy', 'message': 'Service down'}
        
        monitor.register_component("healthy_service", healthy_component)
        monitor.register_component("unhealthy_service", unhealthy_component)
        
        monitor._perform_health_checks()
        
        assert len(monitor.health_checks) >= 2
        return True
    except Exception as e:
        print(f"Health checks failed: {e}")
        return False


def test_alert_generation() -> bool:
    """Test alert generation"""
    try:
        monitor = KGASSystemMonitor()
        
        monitor._generate_alert("test_alert", "Test message", {"test": True})
        assert len(monitor.alerts) >= 1
        return True
    except Exception as e:
        print(f"Alert generation failed: {e}")
        return False


def test_system_metrics() -> bool:
    """Test system metrics collection"""
    try:
        monitor = KGASSystemMonitor()
        monitor._collect_system_metrics()
        
        # Should have collected some system metrics
        assert len(monitor.metrics) > 0
        
        # Check for some expected metrics
        metric_names = set([m.name for m in monitor.metrics])
        expected_metrics = ["cpu_percent", "memory_percent", "process_count"]
        
        for expected in expected_metrics:
            assert expected in metric_names, f"Missing metric: {expected}"
        
        return True
    except Exception as e:
        print(f"System metrics failed: {e}")
        return False


def test_performance_tracking() -> bool:
    """Test performance tracking"""
    try:
        monitor = KGASSystemMonitor()
        
        monitor.record_document_processed(1.5, 25)
        monitor.record_database_operation("insert", True, 0.1)
        monitor.record_error("test_error", {"severity": "warning"})
        
        assert monitor.documents_processed == 1
        assert monitor.entities_extracted == 25
        assert monitor.database_operations == 1
        assert monitor.errors_count == 1
        
        return True
    except Exception as e:
        print(f"Performance tracking failed: {e}")
        return False


def test_monitoring_reports() -> bool:
    """Test monitoring report generation"""
    try:
        temp_dir = Path(tempfile.mkdtemp())
        config = {'output_dir': str(temp_dir / 'reports')}
        monitor = KGASSystemMonitor(config)
        
        monitor.record_document_processed(1.5, 20)
        
        report_file = monitor.generate_monitoring_report("test_report")
        assert report_file.exists()
        
        with open(report_file, 'r') as f:
            report_data = json.load(f)
        
        assert "health_status" in report_data
        assert "metrics_summary" in report_data
        
        return True
    except Exception as e:
        print(f"Monitoring reports failed: {e}")
        return False


def test_dashboard_data() -> bool:
    """Test dashboard data generation"""
    try:
        monitor = KGASSystemMonitor()
        
        monitor._record_metric("cpu_percent", 25.0, MetricType.GAUGE, {"type": "system"})
        monitor.record_document_processed(1.5, 25)
        
        dashboard_data = monitor.get_dashboard_data()
        
        required_sections = ["health_status", "charts", "alerts", "summary"]
        for section in required_sections:
            assert section in dashboard_data, f"Missing section: {section}"
        
        return True
    except Exception as e:
        print(f"Dashboard data failed: {e}")
        return False


def main():
    """Main test execution"""
    try:
        success = run_comprehensive_test()
        
        if success:
            print("\nüéâ ALL SYSTEM MONITORING TESTS PASSED!")
            print("‚úÖ Phase 9.2: System monitoring implementation complete")
            return 0
        else:
            print("\n‚ùå SOME SYSTEM MONITORING TESTS FAILED!")
            return 1
            
    except Exception as e:
        print(f"\nüí• TEST SUITE EXECUTION FAILED: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())