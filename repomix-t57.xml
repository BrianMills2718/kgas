This file is a merged representation of a subset of the codebase, containing specifically included files and files not matching ignore patterns, combined into a single document by Repomix.
The content has been processed where empty lines have been removed.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of a subset of the repository's contents that is considered the most important context.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: src/tools/phase2/t57_path_analysis_unified.py, tests/unit/test_t57_path_analysis_unified.py
- Files matching these patterns are excluded: *.md, Evidence_*, logs/*, *.log, archived/*, docs/analysis/*, *.xml, .gemini-cache/*, __pycache__/*
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Empty lines have been removed from all files
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
src/
  tools/
    phase2/
      t57_path_analysis_unified.py
tests/
  unit/
    test_t57_path_analysis_unified.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="src/tools/phase2/t57_path_analysis_unified.py">
"""
T57 Path Analysis Tool - Advanced Path and Flow Analysis
========================================================
Implements comprehensive path analysis algorithms for graph networks including:
- Shortest path algorithms (Dijkstra, A*, Floyd-Warshall)
- All-pairs shortest paths and path enumeration
- Flow analysis (maximum flow, minimum cut)
- Path centrality and betweenness analysis
- Reachability analysis and connectivity metrics
- Multi-source path analysis with batch processing
Key Features:
- Real NetworkX algorithms for path computation
- Multiple path algorithms with performance optimization
- Academic-quality path analysis with statistical metrics
- Publication-ready output with path visualizations
- Zero-mocking test implementation
Author: Claude Code Assistant
Version: 1.0.0
Phase: 2.1 (Advanced Graph Analytics)
"""
import networkx as nx
import numpy as np
import pandas as pd
from typing import Dict, List, Any, Optional, Tuple, Union, Set
from dataclasses import dataclass, asdict
from enum import Enum
import time
import logging
from datetime import datetime
from src.tools.base_tool import BaseTool, ToolRequest, ToolResult, ToolContract
from src.core.service_manager import ServiceManager
class PathAlgorithm(Enum):
    """Supported path algorithms"""
    DIJKSTRA = "dijkstra"
    BELLMAN_FORD = "bellman_ford"
    FLOYD_WARSHALL = "floyd_warshall"
    ASTAR = "astar"
    BFS = "bfs"
    DFS = "dfs"
    SHORTEST_PATH = "shortest_path"
    ALL_PAIRS = "all_pairs"
class FlowAlgorithm(Enum):
    """Supported flow algorithms"""
    FORD_FULKERSON = "ford_fulkerson"
    EDMONDS_KARP = "edmonds_karp"
    DINIC = "dinic"
    PUSH_RELABEL = "push_relabel"
    MINIMUM_CUT = "minimum_cut"
@dataclass
class PathInstance:
    """Represents a single path in the graph"""
    source: str
    target: str
    path: List[str]
    length: int
    weight: float
    algorithm: str
    execution_time: float
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)
@dataclass
class FlowResult:
    """Represents flow analysis results"""
    source: str
    sink: str
    max_flow_value: float
    flow_paths: List[Dict[str, Any]]
    min_cut_edges: List[Tuple[str, str]]
    algorithm: str
    execution_time: float
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)
@dataclass
class PathStats:
    """Statistical summary of path analysis"""
    total_paths: int
    avg_path_length: float
    max_path_length: int
    min_path_length: int
    path_length_distribution: Dict[int, int]
    diameter: int
    radius: int
    eccentricity_stats: Dict[str, float]
    connectivity_ratio: float
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)
class PathAnalysisTool(BaseTool):
    """
    Advanced Path Analysis Tool for Graph Networks
    Provides comprehensive path analysis capabilities including shortest paths,
    flow analysis, reachability, and connectivity metrics using real NetworkX algorithms.
    """
    def __init__(self, service_manager: ServiceManager):
        super().__init__(service_manager)
        self.tool_id = "T57_PATH_ANALYSIS"
        self.name = "Advanced Path Analysis"
        self.category = "advanced_analytics"
        self.requires_large_data = True
        self.supports_batch_processing = True
        self.academic_output_ready = True
        # Path algorithm configurations
        self.path_algorithms = {
            PathAlgorithm.DIJKSTRA: {
                "weighted": True,
                "negative_weights": False,
                "all_pairs": False,
                "heuristic": False
            },
            PathAlgorithm.BELLMAN_FORD: {
                "weighted": True,
                "negative_weights": True,
                "all_pairs": False,
                "heuristic": False
            },
            PathAlgorithm.FLOYD_WARSHALL: {
                "weighted": True,
                "negative_weights": True,
                "all_pairs": True,
                "heuristic": False
            },
            PathAlgorithm.ASTAR: {
                "weighted": True,
                "negative_weights": False,
                "all_pairs": False,
                "heuristic": True
            },
            PathAlgorithm.BFS: {
                "weighted": False,
                "negative_weights": False,
                "all_pairs": False,
                "heuristic": False
            }
        }
        # Flow algorithm configurations
        self.flow_algorithms = {
            FlowAlgorithm.FORD_FULKERSON: {"method": "ford_fulkerson"},
            FlowAlgorithm.EDMONDS_KARP: {"method": "edmonds_karp"},
            FlowAlgorithm.DINIC: {"method": "dinic"},
            FlowAlgorithm.PUSH_RELABEL: {"method": "push_relabel"}
        }
        self.logger = logging.getLogger(__name__)
    def get_contract(self) -> ToolContract:
        """Return the tool contract defining inputs, outputs, and requirements"""
        return ToolContract(
            tool_id=self.tool_id,
            name=self.name,
            description="Advanced path analysis and flow computation for graph networks",
            category=self.category,
            input_schema={
                "type": "object",
                "properties": {
                    "graph_source": {
                        "type": "string",
                        "enum": ["networkx", "edge_list", "adjacency_matrix", "file"],
                        "description": "Source format of the graph data"
                    },
                    "graph_data": {
                        "type": "object",
                        "description": "Graph data in specified format"
                    },
                    "analysis_type": {
                        "type": "string",
                        "enum": ["shortest_paths", "all_pairs", "flow_analysis", "reachability", "comprehensive"],
                        "default": "shortest_paths",
                        "description": "Type of path analysis to perform"
                    },
                    "source_nodes": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "Source nodes for path analysis"
                    },
                    "target_nodes": {
                        "type": "array", 
                        "items": {"type": "string"},
                        "description": "Target nodes for path analysis"
                    },
                    "algorithms": {
                        "type": "array",
                        "items": {"type": "string"},
                        "default": ["dijkstra"],
                        "description": "Path algorithms to use"
                    },
                    "flow_algorithm": {
                        "type": "string",
                        "enum": ["ford_fulkerson", "edmonds_karp", "dinic", "push_relabel"],
                        "default": "edmonds_karp",
                        "description": "Flow algorithm for flow analysis"
                    },
                    "weighted": {
                        "type": "boolean",
                        "default": True,
                        "description": "Whether to consider edge weights"
                    },
                    "directed": {
                        "type": "boolean",
                        "default": False,
                        "description": "Whether graph is directed"
                    },
                    "k_paths": {
                        "type": "integer",
                        "minimum": 1,
                        "maximum": 100,
                        "default": 1,
                        "description": "Number of alternative paths to find"
                    },
                    "max_path_length": {
                        "type": "integer",
                        "minimum": 1,
                        "default": 50,
                        "description": "Maximum path length to consider"
                    },
                    "performance_mode": {
                        "type": "string",
                        "enum": ["fast", "balanced", "thorough"],
                        "default": "balanced",
                        "description": "Performance vs thoroughness tradeoff"
                    },
                    "output_format": {
                        "type": "string",
                        "enum": ["detailed", "summary", "paths_only", "statistics_only"],
                        "default": "detailed",
                        "description": "Output format preference"
                    }
                },
                "required": ["graph_source", "graph_data"]
            },
            output_schema={
                "type": "object",
                "properties": {
                    "path_instances": {
                        "type": "array",
                        "items": {"type": "object"},
                        "description": "Individual path instances found"
                    },
                    "path_stats": {
                        "type": "object",
                        "description": "Statistical summary of path analysis"
                    },
                    "flow_results": {
                        "type": "array",
                        "items": {"type": "object"},
                        "description": "Flow analysis results if requested"
                    },
                    "reachability_matrix": {
                        "type": "object",
                        "description": "Node reachability information"
                    },
                    "algorithm_info": {
                        "type": "object",
                        "description": "Algorithm execution details and parameters"
                    },
                    "performance_metrics": {
                        "type": "object",
                        "description": "Execution performance statistics"
                    }
                }
            },
            dependencies=["networkx", "numpy", "pandas"],
            performance_requirements={
                "max_execution_time": 600.0,  # 10 minutes
                "max_memory_mb": 4000,  # 4GB
                "min_accuracy": 0.98
            }
        )
    def execute(self, request: ToolRequest) -> ToolResult:
        """Execute path analysis with specified algorithms and parameters"""
        self._start_execution()
        try:
            # Validate input data
            validation_result = self._validate_input_data(request.input_data)
            if not validation_result["valid"]:
                return self._create_error_result(request, validation_result["error"])
            # Parse input parameters
            graph_source = request.input_data["graph_source"]
            graph_data = request.input_data["graph_data"]
            analysis_type = request.input_data.get("analysis_type", "shortest_paths")
            algorithms = request.input_data.get("algorithms", ["dijkstra"])
            performance_mode = request.input_data.get("performance_mode", "balanced")
            output_format = request.input_data.get("output_format", "detailed")
            # Create graph from input data
            graph = self._create_graph_from_data(graph_source, graph_data, request.input_data)
            if graph is None:
                return self._create_error_result(request, "Failed to create graph from input data", "GRAPH_CREATION_ERROR")
            # Perform path analysis based on type
            result_data = {}
            if analysis_type in ["shortest_paths", "comprehensive"]:
                path_results = self._analyze_shortest_paths(graph, request.input_data, algorithms)
                result_data.update(path_results)
            if analysis_type in ["all_pairs", "comprehensive"]:
                all_pairs_results = self._analyze_all_pairs_paths(graph, request.input_data)
                result_data["all_pairs_paths"] = all_pairs_results
            if analysis_type in ["flow_analysis", "comprehensive"]:
                flow_results = self._analyze_flows(graph, request.input_data)
                result_data["flow_results"] = flow_results
            if analysis_type in ["reachability", "comprehensive"]:
                reachability_results = self._analyze_reachability(graph, request.input_data)
                result_data["reachability_matrix"] = reachability_results
            # Calculate path statistics
            path_stats = self._calculate_path_statistics(graph, result_data)
            result_data["path_stats"] = path_stats.to_dict()
            # Add algorithm information
            has_weights = False
            if graph.edges():
                first_edge = list(graph.edges(data=True))[0]
                has_weights = "weight" in first_edge[2]
            result_data["algorithm_info"] = {
                "algorithms_used": algorithms,
                "analysis_type": analysis_type,
                "graph_size": graph.number_of_nodes(),
                "edge_count": graph.number_of_edges(),
                "directed": graph.is_directed(),
                "weighted": has_weights,
                "performance_mode": performance_mode,
                "total_paths_analyzed": len(result_data.get("path_instances", [])),
                "execution_timestamp": datetime.now().isoformat()
            }
            # Format output based on preference
            formatted_data = self._format_output(result_data, output_format)
            # Calculate academic confidence
            confidence = self._calculate_academic_confidence(formatted_data, graph)
            # Get execution metrics
            execution_time, memory_used = self._end_execution()
            return ToolResult(
                tool_id=self.tool_id,
                status="success",
                data=formatted_data,
                execution_time=execution_time,
                memory_used=memory_used,
                metadata={
                    "academic_ready": True,
                    "publication_ready": True,
                    "statistical_significance": confidence,
                    "graph_size": graph.number_of_nodes(),
                    "edge_count": graph.number_of_edges(),
                    "paths_analyzed": len(formatted_data.get("path_instances", [])),
                    "algorithms_used": algorithms,
                    "analysis_type": analysis_type,
                    "batch_processed": graph.number_of_nodes() > 1000
                }
            )
        except Exception as e:
            self.logger.error(f"Error in path analysis execution: {str(e)}")
            execution_time, memory_used = self._end_execution()
            return ToolResult(
                tool_id=self.tool_id,
                status="error",
                data={},
                error_code="EXECUTION_ERROR",
                error_message=f"Path analysis failed: {str(e)}",
                execution_time=execution_time,
                memory_used=memory_used
            )
    def _create_error_result(self, request: ToolRequest, error_message: str, error_code: str = "INVALID_INPUT") -> ToolResult:
        """Create error result for validation failures"""
        execution_time, memory_used = self._end_execution()
        return ToolResult(
            tool_id=self.tool_id,
            status="error",
            data={},
            error_code=error_code,
            error_message=error_message,
            execution_time=execution_time,
            memory_used=memory_used
        )
    def _validate_input_data(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """Validate input data for path analysis"""
        try:
            # Check required fields
            if "graph_source" not in input_data:
                return {"valid": False, "error": "graph_source is required"}
            if "graph_data" not in input_data:
                return {"valid": False, "error": "graph_data is required"}
            # Validate graph source
            valid_sources = ["networkx", "edge_list", "adjacency_matrix", "file"]
            if input_data["graph_source"] not in valid_sources:
                return {"valid": False, "error": f"graph_source must be one of {valid_sources}"}
            # Validate algorithms
            if "algorithms" in input_data:
                valid_algorithms = [alg.value for alg in PathAlgorithm]
                for algorithm in input_data["algorithms"]:
                    if algorithm not in valid_algorithms:
                        return {"valid": False, "error": f"algorithm '{algorithm}' not supported. Valid algorithms: {valid_algorithms}"}
            # Validate analysis type
            if "analysis_type" in input_data:
                valid_types = ["shortest_paths", "all_pairs", "flow_analysis", "reachability", "comprehensive"]
                if input_data["analysis_type"] not in valid_types:
                    return {"valid": False, "error": f"analysis_type must be one of {valid_types}"}
            # Validate k_paths parameter
            if "k_paths" in input_data:
                if not isinstance(input_data["k_paths"], int) or input_data["k_paths"] < 1 or input_data["k_paths"] > 100:
                    return {"valid": False, "error": "k_paths must be an integer between 1 and 100"}
            return {"valid": True, "error": None}
        except Exception as e:
            return {"valid": False, "error": f"Validation error: {str(e)}"}
    def _create_graph_from_data(self, graph_source: str, graph_data: Dict[str, Any], input_data: Dict[str, Any]) -> Optional[nx.Graph]:
        """Create NetworkX graph from input data"""
        try:
            directed = input_data.get("directed", False)
            weighted = input_data.get("weighted", True)
            # Create appropriate graph type
            if directed:
                graph = nx.DiGraph()
            else:
                graph = nx.Graph()
            if graph_source == "networkx":
                # NetworkX format with nodes and edges
                if "nodes" in graph_data:
                    graph.add_nodes_from(graph_data["nodes"])
                if "edges" in graph_data:
                    edges = graph_data["edges"]
                    if weighted and len(edges) > 0 and len(edges[0]) > 2:
                        # Weighted edges: (source, target, weight)
                        graph.add_weighted_edges_from(edges)
                    else:
                        # Unweighted edges: (source, target)
                        graph.add_edges_from(edges)
                        if weighted:
                            # Add default weights
                            for edge in graph.edges():
                                graph[edge[0]][edge[1]]["weight"] = 1.0
            elif graph_source == "edge_list":
                # Edge list format
                edges = graph_data["edges"]
                if weighted and len(edges) > 0 and len(edges[0]) > 2:
                    graph.add_weighted_edges_from(edges)
                else:
                    graph.add_edges_from(edges)
                    if weighted:
                        for edge in graph.edges():
                            graph[edge[0]][edge[1]]["weight"] = 1.0
            elif graph_source == "adjacency_matrix":
                # Adjacency matrix format
                matrix = np.array(graph_data["matrix"])
                node_labels = graph_data.get("node_labels", [f"node_{i}" for i in range(len(matrix))])
                graph = nx.from_numpy_array(matrix, create_using=nx.DiGraph if directed else nx.Graph)
                # Relabel nodes with proper labels
                mapping = {i: label for i, label in enumerate(node_labels)}
                graph = nx.relabel_nodes(graph, mapping)
                if not weighted:
                    # Remove weights for unweighted analysis
                    for edge in graph.edges():
                        if "weight" in graph[edge[0]][edge[1]]:
                            del graph[edge[0]][edge[1]]["weight"]
            else:
                raise ValueError(f"Unsupported graph source: {graph_source}")
            # Validate graph has nodes and edges
            if graph.number_of_nodes() == 0:
                raise ValueError("Graph must have at least one node")
            return graph
        except Exception as e:
            self.logger.error(f"Error creating graph: {str(e)}")
            return None
    def _analyze_shortest_paths(self, graph: nx.Graph, input_data: Dict[str, Any], algorithms: List[str]) -> Dict[str, Any]:
        """Analyze shortest paths using specified algorithms"""
        path_instances = []
        # Get source and target nodes
        source_nodes = input_data.get("source_nodes", [])
        target_nodes = input_data.get("target_nodes", [])
        # If no specific nodes provided, use sample of nodes
        if not source_nodes:
            nodes = list(graph.nodes())
            source_nodes = nodes[:min(5, len(nodes))] if len(nodes) > 5 else nodes
        if not target_nodes:
            nodes = list(graph.nodes())
            target_nodes = nodes[-min(5, len(nodes)):] if len(nodes) > 5 else nodes
        weighted = input_data.get("weighted", True)
        weight_attr = "weight" if weighted else None
        for algorithm in algorithms:
            algorithm_start_time = time.time()
            try:
                if algorithm == "dijkstra":
                    paths = self._compute_dijkstra_paths(graph, source_nodes, target_nodes, weight_attr)
                elif algorithm == "bellman_ford":
                    paths = self._compute_bellman_ford_paths(graph, source_nodes, target_nodes, weight_attr)
                elif algorithm == "bfs":
                    paths = self._compute_bfs_paths(graph, source_nodes, target_nodes)
                elif algorithm == "shortest_path":
                    paths = self._compute_generic_shortest_paths(graph, source_nodes, target_nodes, weight_attr)
                else:
                    self.logger.warning(f"Algorithm {algorithm} not implemented, using shortest_path")
                    paths = self._compute_generic_shortest_paths(graph, source_nodes, target_nodes, weight_attr)
                algorithm_time = time.time() - algorithm_start_time
                # Convert to PathInstance objects
                for path_data in paths:
                    path_instance = PathInstance(
                        source=path_data["source"],
                        target=path_data["target"],
                        path=path_data["path"],
                        length=len(path_data["path"]) - 1,
                        weight=path_data["weight"],
                        algorithm=algorithm,
                        execution_time=algorithm_time / len(paths) if paths else algorithm_time
                    )
                    path_instances.append(path_instance.to_dict())
            except Exception as e:
                self.logger.error(f"Error in {algorithm} algorithm: {str(e)}")
                continue
        return {"path_instances": path_instances}
    def _compute_dijkstra_paths(self, graph: nx.Graph, sources: List[str], targets: List[str], weight: Optional[str]) -> List[Dict[str, Any]]:
        """Compute shortest paths using Dijkstra's algorithm"""
        paths = []
        for source in sources:
            if source not in graph:
                continue
            try:
                # Compute single-source shortest paths
                if weight:
                    lengths, path_dict = nx.single_source_dijkstra(graph, source, weight=weight)
                else:
                    lengths, path_dict = nx.single_source_dijkstra(graph, source)
                for target in targets:
                    if target in path_dict and source != target:
                        paths.append({
                            "source": source,
                            "target": target,
                            "path": path_dict[target],
                            "weight": lengths[target]
                        })
            except Exception as e:
                self.logger.error(f"Dijkstra error for source {source}: {str(e)}")
                continue
        return paths
    def _compute_bellman_ford_paths(self, graph: nx.Graph, sources: List[str], targets: List[str], weight: Optional[str]) -> List[Dict[str, Any]]:
        """Compute shortest paths using Bellman-Ford algorithm"""
        paths = []
        for source in sources:
            if source not in graph:
                continue
            try:
                # Bellman-Ford can handle negative weights
                lengths, path_dict = nx.single_source_bellman_ford(graph, source, weight=weight)
                for target in targets:
                    if target in path_dict and source != target:
                        paths.append({
                            "source": source,
                            "target": target,
                            "path": path_dict[target],
                            "weight": lengths[target]
                        })
            except Exception as e:
                self.logger.error(f"Bellman-Ford error for source {source}: {str(e)}")
                # Fallback to Dijkstra if negative cycle detected
                try:
                    if weight:
                        lengths, path_dict = nx.single_source_dijkstra(graph, source, weight=weight)
                    else:
                        lengths, path_dict = nx.single_source_dijkstra(graph, source)
                    for target in targets:
                        if target in path_dict and source != target:
                            paths.append({
                                "source": source,
                                "target": target,
                                "path": path_dict[target],
                                "weight": lengths[target]
                            })
                except:
                    continue
        return paths
    def _compute_bfs_paths(self, graph: nx.Graph, sources: List[str], targets: List[str]) -> List[Dict[str, Any]]:
        """Compute shortest paths using BFS (unweighted)"""
        paths = []
        for source in sources:
            if source not in graph:
                continue
            try:
                # BFS shortest paths
                path_dict = nx.single_source_shortest_path(graph, source)
                lengths = nx.single_source_shortest_path_length(graph, source)
                for target in targets:
                    if target in path_dict and source != target:
                        paths.append({
                            "source": source,
                            "target": target,
                            "path": path_dict[target],
                            "weight": float(lengths[target])
                        })
            except Exception as e:
                self.logger.error(f"BFS error for source {source}: {str(e)}")
                continue
        return paths
    def _compute_generic_shortest_paths(self, graph: nx.Graph, sources: List[str], targets: List[str], weight: Optional[str]) -> List[Dict[str, Any]]:
        """Compute shortest paths using NetworkX generic shortest path"""
        paths = []
        for source in sources:
            for target in targets:
                if source == target or source not in graph or target not in graph:
                    continue
                try:
                    # Generic shortest path
                    path = nx.shortest_path(graph, source, target, weight=weight)
                    length = nx.shortest_path_length(graph, source, target, weight=weight)
                    paths.append({
                        "source": source,
                        "target": target,
                        "path": path,
                        "weight": float(length)
                    })
                except (nx.NetworkXNoPath, nx.NodeNotFound) as e:
                    # No path exists between source and target
                    continue
                except Exception as e:
                    self.logger.error(f"Generic shortest path error for {source} -> {target}: {str(e)}")
                    continue
        return paths
    def _analyze_all_pairs_paths(self, graph: nx.Graph, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze all pairs shortest paths"""
        try:
            weighted = input_data.get("weighted", True)
            weight_attr = "weight" if weighted else None
            # Use appropriate all-pairs algorithm
            if weighted:
                try:
                    paths_with_lengths = dict(nx.all_pairs_dijkstra(graph, weight=weight_attr))
                    # Convert to consistent format
                    paths = {}
                    for source, (lengths, path_dict) in paths_with_lengths.items():
                        paths[source] = (lengths, path_dict)
                except:
                    # Fallback to unweighted if weighted fails
                    path_only = dict(nx.all_pairs_shortest_path(graph))
                    lengths_only = dict(nx.all_pairs_shortest_path_length(graph))
                    # Combine into consistent format
                    paths = {}
                    for source in path_only:
                        paths[source] = (lengths_only[source], path_only[source])
            else:
                path_only = dict(nx.all_pairs_shortest_path(graph))
                lengths_only = dict(nx.all_pairs_shortest_path_length(graph))
                # Combine into consistent format
                paths = {}
                for source in path_only:
                    paths[source] = (lengths_only[source], path_only[source])
            # Convert to summary format
            all_pairs_summary = {
                "total_node_pairs": len(paths),
                "reachable_pairs": 0,
                "average_path_length": 0.0,
                "path_distribution": {},
                "node_statistics": {}
            }
            total_length = 0
            reachable_count = 0
            for source, (lengths, path_dict) in paths.items():
                node_stats = {
                    "outgoing_paths": len(lengths) - 1,  # Exclude self
                    "avg_outgoing_length": 0.0,
                    "max_outgoing_length": 0.0
                }
                if lengths:
                    valid_lengths = [l for t, l in lengths.items() if t != source]
                    if valid_lengths:
                        node_stats["avg_outgoing_length"] = np.mean(valid_lengths)
                        node_stats["max_outgoing_length"] = max(valid_lengths)
                        total_length += sum(valid_lengths)
                        reachable_count += len(valid_lengths)
                all_pairs_summary["node_statistics"][source] = node_stats
            if reachable_count > 0:
                all_pairs_summary["reachable_pairs"] = reachable_count
                all_pairs_summary["average_path_length"] = total_length / reachable_count
            return all_pairs_summary
        except Exception as e:
            self.logger.error(f"Error in all-pairs analysis: {str(e)}")
            return {"error": f"All-pairs analysis failed: {str(e)}"}
    def _analyze_flows(self, graph: nx.Graph, input_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Analyze maximum flows and minimum cuts"""
        flow_results = []
        if not graph.is_directed():
            self.logger.warning("Flow analysis works best with directed graphs")
            return flow_results
        try:
            # Get source and sink nodes
            source_nodes = input_data.get("source_nodes", [])
            target_nodes = input_data.get("target_nodes", [])
            flow_algorithm = input_data.get("flow_algorithm", "edmonds_karp")
            if not source_nodes or not target_nodes:
                # Use degree-based heuristic to find good source/sink candidates
                nodes = list(graph.nodes())
                if len(nodes) >= 2:
                    # High out-degree nodes as sources, high in-degree as sinks
                    out_degrees = graph.out_degree()
                    in_degrees = graph.in_degree()
                    source_nodes = [max(out_degrees, key=lambda x: x[1])[0]]
                    target_nodes = [max(in_degrees, key=lambda x: x[1])[0]]
            for source in source_nodes:
                for sink in target_nodes:
                    if source == sink or source not in graph or sink not in graph:
                        continue
                    try:
                        start_time = time.time()
                        # Compute maximum flow
                        # NetworkX flow algorithms expect 'capacity' attribute, not 'weight'
                        # Copy graph and rename weight to capacity for flow analysis
                        flow_graph = graph.copy()
                        for u, v, data in flow_graph.edges(data=True):
                            if 'weight' in data and 'capacity' not in data:
                                flow_graph[u][v]['capacity'] = data['weight']
                            elif 'capacity' not in data:
                                flow_graph[u][v]['capacity'] = 1.0  # Default capacity
                        if flow_algorithm == "edmonds_karp":
                            flow_value, flow_dict = nx.maximum_flow(flow_graph, source, sink, capacity='capacity', flow_func=nx.algorithms.flow.edmonds_karp)
                        else:
                            flow_value, flow_dict = nx.maximum_flow(flow_graph, source, sink, capacity='capacity')
                        # Compute minimum cut
                        cut_value, partition = nx.minimum_cut(flow_graph, source, sink, capacity='capacity')
                        # Extract flow paths (simplified)
                        flow_paths = []
                        for node, flows in flow_dict.items():
                            for target_node, flow_amount in flows.items():
                                if flow_amount > 0:
                                    flow_paths.append({
                                        "from": node,
                                        "to": target_node,
                                        "flow": flow_amount
                                    })
                        # Extract minimum cut edges
                        reachable, non_reachable = partition
                        cut_edges = []
                        for u in reachable:
                            for v in non_reachable:
                                if graph.has_edge(u, v):
                                    cut_edges.append((u, v))
                        execution_time = time.time() - start_time
                        flow_result = FlowResult(
                            source=source,
                            sink=sink,
                            max_flow_value=flow_value,
                            flow_paths=flow_paths,
                            min_cut_edges=cut_edges,
                            algorithm=flow_algorithm,
                            execution_time=execution_time
                        )
                        flow_results.append(flow_result.to_dict())
                    except Exception as e:
                        self.logger.error(f"Flow analysis error for {source} -> {sink}: {str(e)}")
                        continue
        except Exception as e:
            self.logger.error(f"Error in flow analysis: {str(e)}")
        return flow_results
    def _analyze_reachability(self, graph: nx.Graph, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze node reachability and connectivity"""
        try:
            nodes = list(graph.nodes())
            n_nodes = len(nodes)
            # Create reachability matrix
            reachability_matrix = np.zeros((n_nodes, n_nodes), dtype=bool)
            node_to_index = {node: i for i, node in enumerate(nodes)}
            # Calculate reachability for each node pair
            for i, source in enumerate(nodes):
                try:
                    reachable = set(nx.single_source_shortest_path_length(graph, source).keys())
                    for target in reachable:
                        j = node_to_index[target]
                        reachability_matrix[i, j] = True
                except Exception as e:
                    self.logger.error(f"Reachability error for node {source}: {str(e)}")
                    continue
            # Calculate connectivity statistics
            total_pairs = n_nodes * (n_nodes - 1)  # Exclude self-loops
            reachable_pairs = np.sum(reachability_matrix) - n_nodes  # Exclude diagonal
            connectivity_ratio = reachable_pairs / total_pairs if total_pairs > 0 else 0.0
            # Calculate strongly connected components for directed graphs
            if graph.is_directed():
                try:
                    scc = list(nx.strongly_connected_components(graph))
                    scc_info = {
                        "num_components": len(scc),
                        "largest_component_size": max(len(comp) for comp in scc) if scc else 0,
                        "components": [list(comp) for comp in scc]
                    }
                except:
                    scc_info = {"error": "Could not compute strongly connected components"}
            else:
                try:
                    cc = list(nx.connected_components(graph))
                    scc_info = {
                        "num_components": len(cc),
                        "largest_component_size": max(len(comp) for comp in cc) if cc else 0,
                        "components": [list(comp) for comp in cc]
                    }
                except:
                    scc_info = {"error": "Could not compute connected components"}
            return {
                "reachability_matrix": reachability_matrix.tolist(),
                "node_labels": nodes,
                "connectivity_ratio": connectivity_ratio,
                "reachable_pairs": int(reachable_pairs),
                "total_pairs": total_pairs,
                "connectivity_components": scc_info
            }
        except Exception as e:
            self.logger.error(f"Error in reachability analysis: {str(e)}")
            return {"error": f"Reachability analysis failed: {str(e)}"}
    def _calculate_path_statistics(self, graph: nx.Graph, result_data: Dict[str, Any]) -> PathStats:
        """Calculate comprehensive path statistics"""
        try:
            path_instances = result_data.get("path_instances", [])
            if not path_instances:
                # Return empty statistics
                return PathStats(
                    total_paths=0,
                    avg_path_length=0.0,
                    max_path_length=0,
                    min_path_length=0,
                    path_length_distribution={},
                    diameter=0,
                    radius=0,
                    eccentricity_stats={},
                    connectivity_ratio=0.0
                )
            # Basic path statistics
            path_lengths = [p["length"] for p in path_instances]
            total_paths = len(path_instances)
            avg_path_length = np.mean(path_lengths) if path_lengths else 0.0
            max_path_length = max(path_lengths) if path_lengths else 0
            min_path_length = min(path_lengths) if path_lengths else 0
            # Path length distribution
            length_distribution = {}
            for length in path_lengths:
                length_distribution[length] = length_distribution.get(length, 0) + 1
            # Graph-level statistics
            try:
                if nx.is_connected(graph) or (graph.is_directed() and nx.is_weakly_connected(graph)):
                    diameter = nx.diameter(graph)
                    radius = nx.radius(graph)
                    eccentricity = nx.eccentricity(graph)
                    eccentricity_stats = {
                        "mean": np.mean(list(eccentricity.values())),
                        "std": np.std(list(eccentricity.values())),
                        "min": min(eccentricity.values()),
                        "max": max(eccentricity.values())
                    }
                else:
                    diameter = 0
                    radius = 0
                    eccentricity_stats = {}
            except:
                diameter = 0
                radius = 0
                eccentricity_stats = {}
            # Connectivity ratio
            n_nodes = graph.number_of_nodes()
            max_possible_paths = n_nodes * (n_nodes - 1)
            connectivity_ratio = total_paths / max_possible_paths if max_possible_paths > 0 else 0.0
            return PathStats(
                total_paths=total_paths,
                avg_path_length=float(avg_path_length),
                max_path_length=max_path_length,
                min_path_length=min_path_length,
                path_length_distribution=length_distribution,
                diameter=diameter,
                radius=radius,
                eccentricity_stats=eccentricity_stats,
                connectivity_ratio=float(connectivity_ratio)
            )
        except Exception as e:
            self.logger.error(f"Error calculating path statistics: {str(e)}")
            # Return minimal statistics on error
            return PathStats(
                total_paths=0,
                avg_path_length=0.0,
                max_path_length=0,
                min_path_length=0,
                path_length_distribution={},
                diameter=0,
                radius=0,
                eccentricity_stats={},
                connectivity_ratio=0.0
            )
    def _format_output(self, result_data: Dict[str, Any], output_format: str) -> Dict[str, Any]:
        """Format output based on specified format preference"""
        if output_format == "detailed":
            return result_data
        elif output_format == "summary":
            # Return only high-level statistics
            return {
                "path_stats": result_data.get("path_stats", {}),
                "algorithm_info": result_data.get("algorithm_info", {}),
                "summary": {
                    "total_paths": len(result_data.get("path_instances", [])),
                    "flow_analyses": len(result_data.get("flow_results", [])),
                    "reachability_computed": "reachability_matrix" in result_data
                }
            }
        elif output_format == "paths_only":
            # Return only path instances
            return {
                "path_instances": result_data.get("path_instances", []),
                "algorithm_info": result_data.get("algorithm_info", {})
            }
        elif output_format == "statistics_only":
            # Return only statistics
            return {
                "path_stats": result_data.get("path_stats", {}),
                "reachability_matrix": result_data.get("reachability_matrix", {}),
                "algorithm_info": result_data.get("algorithm_info", {})
            }
        else:
            return result_data
    def _calculate_academic_confidence(self, result_data: Dict[str, Any], graph: nx.Graph) -> float:
        """Calculate academic confidence score based on analysis quality"""
        try:
            confidence_factors = []
            # Graph size factor (larger graphs = more confidence)
            n_nodes = graph.number_of_nodes()
            n_edges = graph.number_of_edges()
            if n_nodes >= 10:
                confidence_factors.append(0.3)  # Good size
            elif n_nodes >= 5:
                confidence_factors.append(0.2)  # Moderate size
            else:
                confidence_factors.append(0.1)  # Small size
            # Edge density factor
            max_edges = n_nodes * (n_nodes - 1) / 2 if not graph.is_directed() else n_nodes * (n_nodes - 1)
            if max_edges > 0:
                edge_density = n_edges / max_edges
                if 0.1 <= edge_density <= 0.5:
                    confidence_factors.append(0.2)  # Good density
                else:
                    confidence_factors.append(0.1)  # Too sparse or too dense
            # Path analysis completeness
            path_instances = result_data.get("path_instances", [])
            if len(path_instances) >= 5:
                confidence_factors.append(0.2)  # Good path coverage
            elif len(path_instances) >= 1:
                confidence_factors.append(0.1)  # Some paths found
            # Algorithm diversity
            algorithms_used = set()
            for path in path_instances:
                algorithms_used.add(path.get("algorithm", "unknown"))
            if len(algorithms_used) >= 2:
                confidence_factors.append(0.2)  # Multiple algorithms
            elif len(algorithms_used) == 1:
                confidence_factors.append(0.1)  # Single algorithm
            # Statistical validity
            path_stats = result_data.get("path_stats", {})
            if path_stats.get("total_paths", 0) > 0:
                confidence_factors.append(0.1)  # Has statistics
            return min(sum(confidence_factors), 1.0)
        except Exception as e:
            self.logger.error(f"Error calculating academic confidence: {str(e)}")
            return 0.5  # Default moderate confidence
    def health_check(self) -> ToolResult:
        """Perform health check of the path analysis tool"""
        try:
            import networkx as nx
            import numpy as np
            # Test basic NetworkX functionality
            test_graph = nx.path_graph(3)
            path = nx.shortest_path(test_graph, 0, 2)
            # Test numpy functionality
            test_array = np.array([1, 2, 3])
            mean_val = np.mean(test_array)
            return ToolResult(
                tool_id=self.tool_id,
                status="success",
                data={
                    "healthy": True,
                    "status": "ready",
                    "dependencies": {
                        "networkx": "available",
                        "numpy": "available"
                    },
                    "capabilities": {
                        "path_algorithms": len(self.path_algorithms),
                        "flow_algorithms": len(self.flow_algorithms),
                        "graph_types_supported": ["directed", "undirected", "weighted", "unweighted"]
                    }
                },
                execution_time=0.0,
                memory_used=0
            )
        except Exception as e:
            return ToolResult(
                tool_id=self.tool_id,
                status="error",
                data={
                    "healthy": False,
                    "status": "error",
                    "error": str(e)
                },
                error_code="HEALTH_CHECK_FAILED",
                error_message=f"Health check failed: {str(e)}",
                execution_time=0.0,
                memory_used=0
            )
    def validate_input(self, input_data: Any) -> bool:
        """Validate input data format and content"""
        try:
            if not isinstance(input_data, dict):
                return False
            validation_result = self._validate_input_data(input_data)
            return validation_result["valid"]
        except Exception:
            return False
</file>

<file path="tests/unit/test_t57_path_analysis_unified.py">
"""
Comprehensive unit tests for T57 Path Analysis Tool - ZERO MOCKING
Tests real path analysis algorithms with real NetworkX graphs and academic validation.
"""
import pytest
import networkx as nx
import numpy as np
from typing import Dict, List, Any
import time
# Import the tool to test
from src.tools.phase2.t57_path_analysis_unified import (
    PathAnalysisTool, PathInstance, FlowResult, PathStats, PathAlgorithm, FlowAlgorithm
)
from src.tools.base_tool import ToolRequest, ToolResult, ToolContract
from src.core.service_manager import ServiceManager
class TestT57PathAnalysisUnified:
    """Comprehensive test suite for T57 Path Analysis Tool"""
    def setup_method(self):
        """Setup for each test method - NO MOCKS"""
        # Real ServiceManager - NO mocks
        self.service_manager = ServiceManager()
        self.tool = PathAnalysisTool(service_manager=self.service_manager)
        # Real test graphs
        self.test_graphs = self._create_real_test_graphs()
    def _create_real_test_graphs(self) -> Dict[str, nx.Graph]:
        """Create real test graphs with known path structures"""
        graphs = {}
        # Simple path graph - clear shortest paths
        path_graph = nx.path_graph(5)
        graphs["path"] = path_graph
        # Cycle graph - alternative paths
        cycle_graph = nx.cycle_graph(6)
        graphs["cycle"] = cycle_graph
        # Grid graph - multiple path options
        grid_graph = nx.grid_2d_graph(4, 4)
        # Convert to string labels
        grid_relabeled = nx.Graph()
        for node in grid_graph.nodes():
            grid_relabeled.add_node(f"n_{node[0]}_{node[1]}")
        for edge in grid_graph.edges():
            u, v = edge
            grid_relabeled.add_edge(f"n_{u[0]}_{u[1]}", f"n_{v[0]}_{v[1]}")
        graphs["grid"] = grid_relabeled
        # Weighted graph - different shortest paths
        weighted_graph = nx.Graph()
        weighted_graph.add_weighted_edges_from([
            ("A", "B", 2.0),
            ("A", "C", 5.0),
            ("B", "C", 1.0),
            ("B", "D", 3.0),
            ("C", "D", 1.0),
            ("C", "E", 4.0),
            ("D", "E", 1.0)
        ])
        graphs["weighted"] = weighted_graph
        # Directed graph for flow analysis
        directed_graph = nx.DiGraph()
        directed_graph.add_weighted_edges_from([
            ("S", "A", 10),
            ("S", "B", 8),
            ("A", "B", 5),
            ("A", "C", 8),
            ("B", "C", 3),
            ("B", "D", 5),
            ("C", "T", 10),
            ("D", "T", 8)
        ])
        graphs["directed"] = directed_graph
        # Disconnected graph - unreachable nodes
        disconnected_graph = nx.Graph()
        disconnected_graph.add_edges_from([
            ("A", "B"), ("B", "C"),  # Component 1
            ("D", "E"), ("E", "F")   # Component 2
        ])
        graphs["disconnected"] = disconnected_graph
        # Complete graph - many paths
        complete_graph = nx.complete_graph(6)
        graphs["complete"] = complete_graph
        # Tree graph - unique paths
        tree_graph = nx.balanced_tree(2, 3)
        graphs["tree"] = tree_graph
        # Academic collaboration network
        collab_graph = nx.Graph()
        researchers = [f"researcher_{i}" for i in range(12)]
        collab_graph.add_nodes_from(researchers)
        # Create realistic collaboration patterns
        collaborations = [
            # Core research group
            ("researcher_0", "researcher_1"), ("researcher_1", "researcher_2"),
            ("researcher_2", "researcher_3"), ("researcher_0", "researcher_3"),
            # Extended collaborations
            ("researcher_1", "researcher_4"), ("researcher_4", "researcher_5"),
            ("researcher_2", "researcher_6"), ("researcher_6", "researcher_7"),
            # Cross-group links
            ("researcher_4", "researcher_8"), ("researcher_8", "researcher_9"),
            ("researcher_7", "researcher_10"), ("researcher_10", "researcher_11"),
            # Bridge connections
            ("researcher_5", "researcher_10"), ("researcher_8", "researcher_6")
        ]
        collab_graph.add_edges_from(collaborations)
        graphs["collaboration"] = collab_graph
        return graphs
    def test_tool_initialization(self):
        """Test tool initializes correctly with real service manager"""
        assert self.tool.tool_id == "T57_PATH_ANALYSIS"
        assert self.tool.name == "Advanced Path Analysis"
        assert self.tool.category == "advanced_analytics"
        assert self.tool.requires_large_data is True
        assert self.tool.supports_batch_processing is True
        assert self.tool.academic_output_ready is True
        assert isinstance(self.tool.path_algorithms, dict)
        assert isinstance(self.tool.flow_algorithms, dict)
        assert len(self.tool.path_algorithms) >= 5  # At least 5 path algorithms
    def test_get_contract(self):
        """Test tool contract is properly defined"""
        contract = self.tool.get_contract()
        assert isinstance(contract, ToolContract)
        assert contract.tool_id == "T57_PATH_ANALYSIS"
        assert contract.name == "Advanced Path Analysis"
        assert contract.category == "advanced_analytics"
        # Validate input schema
        assert "graph_source" in contract.input_schema["properties"]
        assert "analysis_type" in contract.input_schema["properties"]
        assert "algorithms" in contract.input_schema["properties"]
        assert "source_nodes" in contract.input_schema["properties"]
        assert "target_nodes" in contract.input_schema["properties"]
        # Validate output schema
        assert "path_instances" in contract.output_schema["properties"]
        assert "path_stats" in contract.output_schema["properties"]
        assert "algorithm_info" in contract.output_schema["properties"]
        # Validate dependencies
        assert "networkx" in contract.dependencies
        assert "numpy" in contract.dependencies
        # Validate performance requirements
        assert contract.performance_requirements["max_execution_time"] == 600.0
        assert contract.performance_requirements["max_memory_mb"] == 4000
        assert contract.performance_requirements["min_accuracy"] == 0.98
    def test_dijkstra_shortest_paths_real(self):
        """Test Dijkstra shortest path algorithm with real graph"""
        weighted_graph = self.test_graphs["weighted"]
        request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "networkx",
                "graph_data": {
                    "nodes": list(weighted_graph.nodes()),
                    "edges": [(u, v, d["weight"]) for u, v, d in weighted_graph.edges(data=True)]
                },
                "analysis_type": "shortest_paths",
                "source_nodes": ["A"],
                "target_nodes": ["E"],
                "algorithms": ["dijkstra"],
                "weighted": True
            },
            parameters={}
        )
        result = self.tool.execute(request)
        assert result.status == "success"
        assert "path_instances" in result.data
        path_instances = result.data["path_instances"]
        assert len(path_instances) > 0
        # Find A -> E path
        ae_paths = [p for p in path_instances if p["source"] == "A" and p["target"] == "E"]
        assert len(ae_paths) >= 1
        ae_path = ae_paths[0]
        assert ae_path["algorithm"] == "dijkstra"
        assert ae_path["source"] == "A"
        assert ae_path["target"] == "E"
        assert len(ae_path["path"]) >= 2
        assert ae_path["weight"] > 0
        # Verify path is valid
        path = ae_path["path"]
        assert path[0] == "A"
        assert path[-1] == "E"
    def test_bfs_shortest_paths_real(self):
        """Test BFS shortest path algorithm with real graph"""
        path_graph = self.test_graphs["path"]
        request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "networkx",
                "graph_data": {
                    "nodes": list(path_graph.nodes()),
                    "edges": list(path_graph.edges())
                },
                "analysis_type": "shortest_paths",
                "source_nodes": [0],
                "target_nodes": [4],
                "algorithms": ["bfs"],
                "weighted": False
            },
            parameters={}
        )
        result = self.tool.execute(request)
        assert result.status == "success"
        path_instances = result.data["path_instances"]
        assert len(path_instances) > 0
        # Find 0 -> 4 path
        path_04 = [p for p in path_instances if p["source"] == 0 and p["target"] == 4][0]
        assert path_04["algorithm"] == "bfs"
        assert path_04["length"] == 4  # Path graph 0-1-2-3-4 has length 4
        assert path_04["path"] == [0, 1, 2, 3, 4]
    def test_multiple_algorithms_comparison_real(self):
        """Test multiple algorithms on same graph for comparison"""
        weighted_graph = self.test_graphs["weighted"]
        request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "networkx",
                "graph_data": {
                    "nodes": list(weighted_graph.nodes()),
                    "edges": [(u, v, d["weight"]) for u, v, d in weighted_graph.edges(data=True)]
                },
                "analysis_type": "shortest_paths",
                "source_nodes": ["A"],
                "target_nodes": ["D"],
                "algorithms": ["dijkstra", "bellman_ford", "shortest_path"],
                "weighted": True
            },
            parameters={}
        )
        result = self.tool.execute(request)
        assert result.status == "success"
        path_instances = result.data["path_instances"]
        # Should have paths from all algorithms
        algorithms_used = set(p["algorithm"] for p in path_instances)
        assert len(algorithms_used) >= 2  # At least 2 algorithms worked
        # All algorithms should find the same shortest path weight (optimality)
        ad_paths = [p for p in path_instances if p["source"] == "A" and p["target"] == "D"]
        if len(ad_paths) > 1:
            weights = [p["weight"] for p in ad_paths]
            # All should find the optimal path weight (allowing small floating point differences)
            assert max(weights) - min(weights) < 0.01
    def test_all_pairs_analysis_real(self):
        """Test all-pairs shortest path analysis"""
        cycle_graph = self.test_graphs["cycle"]
        request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "networkx",
                "graph_data": {
                    "nodes": list(cycle_graph.nodes()),
                    "edges": list(cycle_graph.edges())
                },
                "analysis_type": "all_pairs",
                "weighted": False
            },
            parameters={}
        )
        result = self.tool.execute(request)
        assert result.status == "success"
        assert "all_pairs_paths" in result.data
        all_pairs = result.data["all_pairs_paths"]
        assert "total_node_pairs" in all_pairs
        assert "reachable_pairs" in all_pairs
        assert "average_path_length" in all_pairs
        assert "node_statistics" in all_pairs
        # Cycle graph should have good connectivity
        assert all_pairs["reachable_pairs"] > 0
        assert all_pairs["average_path_length"] > 0
        # Each node should have statistics
        assert len(all_pairs["node_statistics"]) == cycle_graph.number_of_nodes()
    def test_flow_analysis_real(self):
        """Test flow analysis with real directed graph"""
        directed_graph = self.test_graphs["directed"]
        request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "networkx",
                "graph_data": {
                    "nodes": list(directed_graph.nodes()),
                    "edges": [(u, v, d["weight"]) for u, v, d in directed_graph.edges(data=True)]
                },
                "analysis_type": "flow_analysis",
                "source_nodes": ["S"],
                "target_nodes": ["T"],
                "flow_algorithm": "edmonds_karp",
                "directed": True,
                "weighted": True
            },
            parameters={}
        )
        result = self.tool.execute(request)
        assert result.status == "success"
        assert "flow_results" in result.data
        flow_results = result.data["flow_results"]
        assert len(flow_results) > 0
        # Find S -> T flow
        st_flows = [f for f in flow_results if f["source"] == "S" and f["sink"] == "T"]
        assert len(st_flows) >= 1
        st_flow = st_flows[0]
        assert st_flow["max_flow_value"] > 0
        assert "flow_paths" in st_flow
        assert "min_cut_edges" in st_flow
        assert st_flow["algorithm"] == "edmonds_karp"
        assert st_flow["execution_time"] >= 0
    def test_reachability_analysis_real(self):
        """Test reachability analysis with real graph"""
        disconnected_graph = self.test_graphs["disconnected"]
        request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "networkx",
                "graph_data": {
                    "nodes": list(disconnected_graph.nodes()),
                    "edges": list(disconnected_graph.edges())
                },
                "analysis_type": "reachability",
                "weighted": False
            },
            parameters={}
        )
        result = self.tool.execute(request)
        assert result.status == "success"
        assert "reachability_matrix" in result.data
        reachability = result.data["reachability_matrix"]
        assert "reachability_matrix" in reachability
        assert "node_labels" in reachability
        assert "connectivity_ratio" in reachability
        assert "connectivity_components" in reachability
        # Disconnected graph should have low connectivity ratio
        assert 0 <= reachability["connectivity_ratio"] < 1.0
        # Should detect multiple components
        components = reachability["connectivity_components"]
        assert components["num_components"] >= 2
    def test_comprehensive_analysis_real(self):
        """Test comprehensive analysis combining all analysis types"""
        complete_graph = self.test_graphs["complete"]
        request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "networkx",
                "graph_data": {
                    "nodes": list(complete_graph.nodes()),
                    "edges": list(complete_graph.edges())
                },
                "analysis_type": "comprehensive",
                "algorithms": ["dijkstra", "bfs"],
                "weighted": False,
                "output_format": "detailed"
            },
            parameters={}
        )
        result = self.tool.execute(request)
        assert result.status == "success"
        # Should have all analysis types
        assert "path_instances" in result.data
        assert "all_pairs_paths" in result.data
        assert "reachability_matrix" in result.data
        assert "path_stats" in result.data
        assert "algorithm_info" in result.data
        # Complete graph should have excellent connectivity
        reachability = result.data["reachability_matrix"]
        assert reachability["connectivity_ratio"] > 0.9
        # Should have many path instances
        path_instances = result.data["path_instances"]
        assert len(path_instances) > 0
    def test_edge_list_input_real(self):
        """Test path analysis with edge list input"""
        request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "edge_list",
                "graph_data": {
                    "edges": [("A", "B"), ("B", "C"), ("C", "D"), ("A", "D")]
                },
                "analysis_type": "shortest_paths",
                "source_nodes": ["A"],
                "target_nodes": ["D"],
                "algorithms": ["bfs"],
                "weighted": False
            },
            parameters={}
        )
        result = self.tool.execute(request)
        assert result.status == "success"
        path_instances = result.data["path_instances"]
        assert len(path_instances) > 0
        # Should find A -> D path
        ad_paths = [p for p in path_instances if p["source"] == "A" and p["target"] == "D"]
        assert len(ad_paths) >= 1
        ad_path = ad_paths[0]
        assert ad_path["source"] == "A"
        assert ad_path["target"] == "D"
        assert ad_path["length"] >= 1
    def test_adjacency_matrix_input_real(self):
        """Test path analysis with adjacency matrix input"""
        # 4x4 adjacency matrix
        adj_matrix = [
            [0, 1, 0, 1],
            [1, 0, 1, 0],
            [0, 1, 0, 1],
            [1, 0, 1, 0]
        ]
        request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "adjacency_matrix",
                "graph_data": {
                    "matrix": adj_matrix,
                    "node_labels": ["A", "B", "C", "D"]
                },
                "analysis_type": "shortest_paths",
                "source_nodes": ["A"],
                "target_nodes": ["C"],
                "algorithms": ["bfs"],
                "weighted": False
            },
            parameters={}
        )
        result = self.tool.execute(request)
        assert result.status == "success"
        path_instances = result.data["path_instances"]
        assert len(path_instances) > 0
        # Should find A -> C path
        ac_paths = [p for p in path_instances if p["source"] == "A" and p["target"] == "C"]
        assert len(ac_paths) >= 1
    def test_weighted_vs_unweighted_real(self):
        """Test difference between weighted and unweighted analysis"""
        weighted_graph = self.test_graphs["weighted"]
        # Weighted analysis
        weighted_request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "networkx",
                "graph_data": {
                    "nodes": list(weighted_graph.nodes()),
                    "edges": [(u, v, d["weight"]) for u, v, d in weighted_graph.edges(data=True)]
                },
                "analysis_type": "shortest_paths",
                "source_nodes": ["A"],
                "target_nodes": ["E"],
                "algorithms": ["dijkstra"],
                "weighted": True
            },
            parameters={}
        )
        # Unweighted analysis
        unweighted_request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "networkx",
                "graph_data": {
                    "nodes": list(weighted_graph.nodes()),
                    "edges": list(weighted_graph.edges())
                },
                "analysis_type": "shortest_paths",
                "source_nodes": ["A"],
                "target_nodes": ["E"],
                "algorithms": ["bfs"],
                "weighted": False
            },
            parameters={}
        )
        weighted_result = self.tool.execute(weighted_request)
        unweighted_result = self.tool.execute(unweighted_request)
        assert weighted_result.status == "success"
        assert unweighted_result.status == "success"
        # Both should find paths but potentially different ones
        weighted_paths = [p for p in weighted_result.data["path_instances"] if p["source"] == "A" and p["target"] == "E"]
        unweighted_paths = [p for p in unweighted_result.data["path_instances"] if p["source"] == "A" and p["target"] == "E"]
        assert len(weighted_paths) >= 1
        assert len(unweighted_paths) >= 1
        # Paths might be different due to weight consideration
        weighted_path = weighted_paths[0]["path"]
        unweighted_path = unweighted_paths[0]["path"]
        # Both should start and end correctly
        assert weighted_path[0] == "A" and weighted_path[-1] == "E"
        assert unweighted_path[0] == "A" and unweighted_path[-1] == "E"
    def test_k_paths_parameter_real(self):
        """Test k-paths parameter for alternative path finding"""
        grid_graph = self.test_graphs["grid"]
        request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "networkx",
                "graph_data": {
                    "nodes": list(grid_graph.nodes()),
                    "edges": list(grid_graph.edges())
                },
                "analysis_type": "shortest_paths",
                "source_nodes": ["n_0_0"],
                "target_nodes": ["n_3_3"],
                "algorithms": ["bfs"],
                "k_paths": 3,
                "weighted": False
            },
            parameters={}
        )
        result = self.tool.execute(request)
        assert result.status == "success"
        path_instances = result.data["path_instances"]
        # Should find at least one path
        corner_paths = [p for p in path_instances if p["source"] == "n_0_0" and p["target"] == "n_3_3"]
        assert len(corner_paths) >= 1
        corner_path = corner_paths[0]
        assert corner_path["length"] >= 6  # Manhattan distance in 4x4 grid
    def test_path_statistics_calculation_real(self):
        """Test path statistics calculation with real data"""
        tree_graph = self.test_graphs["tree"]
        request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "networkx",
                "graph_data": {
                    "nodes": list(tree_graph.nodes()),
                    "edges": list(tree_graph.edges())
                },
                "analysis_type": "comprehensive",
                "algorithms": ["bfs"],
                "weighted": False
            },
            parameters={}
        )
        result = self.tool.execute(request)
        assert result.status == "success"
        assert "path_stats" in result.data
        path_stats = result.data["path_stats"]
        assert "total_paths" in path_stats
        assert "avg_path_length" in path_stats
        assert "max_path_length" in path_stats
        assert "min_path_length" in path_stats
        assert "path_length_distribution" in path_stats
        assert "diameter" in path_stats
        assert "connectivity_ratio" in path_stats
        # Tree should have good connectivity
        assert path_stats["total_paths"] > 0
        assert path_stats["avg_path_length"] > 0
        assert path_stats["connectivity_ratio"] > 0
    def test_output_format_variations_real(self):
        """Test different output formats"""
        path_graph = self.test_graphs["path"]
        for output_format in ["detailed", "summary", "paths_only", "statistics_only"]:
            request = ToolRequest(
                tool_id="T57_PATH_ANALYSIS",
                operation="analyze_paths",
                input_data={
                    "graph_source": "networkx",
                    "graph_data": {
                        "nodes": list(path_graph.nodes()),
                        "edges": list(path_graph.edges())
                    },
                    "analysis_type": "shortest_paths",
                    "source_nodes": [0],
                    "target_nodes": [4],
                    "algorithms": ["bfs"],
                    "output_format": output_format,
                    "weighted": False
                },
                parameters={}
            )
            result = self.tool.execute(request)
            assert result.status == "success"
            if output_format == "detailed":
                assert "path_instances" in result.data
                assert "path_stats" in result.data
                assert "algorithm_info" in result.data
            elif output_format == "summary":
                assert "path_stats" in result.data
                assert "algorithm_info" in result.data
                assert "summary" in result.data
            elif output_format == "paths_only":
                assert "path_instances" in result.data
                assert "algorithm_info" in result.data
            elif output_format == "statistics_only":
                assert "path_stats" in result.data
                assert "algorithm_info" in result.data
    def test_performance_requirements_real(self):
        """Test performance meets contract requirements"""
        complete_graph = self.test_graphs["complete"]
        request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "networkx",
                "graph_data": {
                    "nodes": list(complete_graph.nodes()),
                    "edges": list(complete_graph.edges())
                },
                "analysis_type": "shortest_paths",
                "algorithms": ["dijkstra", "bfs"],
                "weighted": False,
                "performance_mode": "fast"
            },
            parameters={}
        )
        start_time = time.time()
        result = self.tool.execute(request)
        execution_time = time.time() - start_time
        assert result.status == "success"
        # Performance requirements from contract
        max_execution_time = 600.0  # 10 minutes
        # Check execution time
        assert execution_time < max_execution_time
        assert result.execution_time < max_execution_time
        # Memory should be reasonable
        assert result.memory_used >= 0
    def test_academic_confidence_calculation_real(self):
        """Test academic confidence calculation with real data"""
        collab_graph = self.test_graphs["collaboration"]
        request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "networkx",
                "graph_data": {
                    "nodes": list(collab_graph.nodes()),
                    "edges": list(collab_graph.edges())
                },
                "analysis_type": "comprehensive",
                "algorithms": ["dijkstra", "bfs"],
                "weighted": False
            },
            parameters={}
        )
        result = self.tool.execute(request)
        assert result.status == "success"
        # Check metadata has academic confidence
        assert "statistical_significance" in result.metadata
        confidence = result.metadata["statistical_significance"]
        # Confidence should be between 0.1 and 1.0
        assert 0.1 <= confidence <= 1.0
        # Academic ready flags should be set
        assert result.metadata["academic_ready"] is True
        assert result.metadata["publication_ready"] is True
    def test_error_handling_invalid_input_real(self):
        """Test error handling with invalid inputs"""
        # Test with missing graph_data
        request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "edge_list",
                "analysis_type": "shortest_paths"
            },
            parameters={}
        )
        result = self.tool.execute(request)
        assert result.status == "error"
        assert result.error_code == "INVALID_INPUT"
        assert "graph_data is required" in result.error_message
        # Test with invalid graph source
        request2 = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "invalid_source",
                "graph_data": {"edges": [("A", "B")]},
                "analysis_type": "shortest_paths"
            },
            parameters={}
        )
        result2 = self.tool.execute(request2)
        assert result2.status == "error"
        assert result2.error_code == "INVALID_INPUT"
        assert "graph_source must be one of" in result2.error_message
    def test_error_handling_invalid_algorithm_real(self):
        """Test error handling with invalid algorithm"""
        path_graph = self.test_graphs["path"]
        request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "networkx",
                "graph_data": {
                    "nodes": list(path_graph.nodes()),
                    "edges": list(path_graph.edges())
                },
                "analysis_type": "shortest_paths",
                "algorithms": ["invalid_algorithm"],
                "weighted": False
            },
            parameters={}
        )
        result = self.tool.execute(request)
        assert result.status == "error"
        assert result.error_code == "INVALID_INPUT"
        assert "algorithm 'invalid_algorithm' not supported" in result.error_message
    def test_error_handling_unreachable_nodes_real(self):
        """Test handling of unreachable node pairs"""
        disconnected_graph = self.test_graphs["disconnected"]
        request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "networkx",
                "graph_data": {
                    "nodes": list(disconnected_graph.nodes()),
                    "edges": list(disconnected_graph.edges())
                },
                "analysis_type": "shortest_paths",
                "source_nodes": ["A"],
                "target_nodes": ["E"],  # E is in different component
                "algorithms": ["bfs"],
                "weighted": False
            },
            parameters={}
        )
        result = self.tool.execute(request)
        # Should succeed but find no paths
        assert result.status == "success"
        path_instances = result.data["path_instances"]
        # Should not find A -> E path (different components)
        ae_paths = [p for p in path_instances if p["source"] == "A" and p["target"] == "E"]
        assert len(ae_paths) == 0
    def test_health_check_real(self):
        """Test tool health check"""
        health_result = self.tool.health_check()
        assert isinstance(health_result, ToolResult)
        assert health_result.tool_id == "T57_PATH_ANALYSIS"
        assert health_result.status == "success"
        assert health_result.data["healthy"] is True
        assert health_result.data["status"] == "ready"
    def test_input_validation_real(self):
        """Test input validation method"""
        # Valid input
        valid_input = {
            "graph_source": "edge_list",
            "graph_data": {"edges": [("A", "B"), ("B", "C")]},
            "analysis_type": "shortest_paths"
        }
        assert self.tool.validate_input(valid_input) is True
        # Invalid input - missing required field
        invalid_input = {
            "analysis_type": "shortest_paths"
        }
        assert self.tool.validate_input(invalid_input) is False
        # Invalid input - wrong type
        assert self.tool.validate_input("not_a_dict") is False
        assert self.tool.validate_input(None) is False
    def test_directed_vs_undirected_analysis_real(self):
        """Test analysis differences between directed and undirected graphs"""
        # Undirected analysis
        cycle_graph = self.test_graphs["cycle"]
        undirected_request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "networkx",
                "graph_data": {
                    "nodes": list(cycle_graph.nodes()),
                    "edges": list(cycle_graph.edges())
                },
                "analysis_type": "reachability",
                "directed": False,
                "weighted": False
            },
            parameters={}
        )
        # Directed analysis
        directed_graph = self.test_graphs["directed"]
        directed_request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "networkx",
                "graph_data": {
                    "nodes": list(directed_graph.nodes()),
                    "edges": [(u, v, d["weight"]) for u, v, d in directed_graph.edges(data=True)]
                },
                "analysis_type": "reachability",
                "directed": True,
                "weighted": True
            },
            parameters={}
        )
        undirected_result = self.tool.execute(undirected_request)
        directed_result = self.tool.execute(directed_request)
        assert undirected_result.status == "success"
        assert directed_result.status == "success"
        # Undirected cycle should have higher connectivity
        undirected_connectivity = undirected_result.data["reachability_matrix"]["connectivity_ratio"]
        directed_connectivity = directed_result.data["reachability_matrix"]["connectivity_ratio"]
        assert 0 <= undirected_connectivity <= 1.0
        assert 0 <= directed_connectivity <= 1.0
    def test_concurrent_execution_safety_real(self):
        """Test tool can handle concurrent executions safely"""
        path_graph = self.test_graphs["path"]
        request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "networkx",
                "graph_data": {
                    "nodes": list(path_graph.nodes()),
                    "edges": list(path_graph.edges())
                },
                "analysis_type": "shortest_paths",
                "source_nodes": [0],
                "target_nodes": [4],
                "algorithms": ["bfs"],
                "weighted": False
            },
            parameters={}
        )
        # Execute multiple times to check for state issues
        results = []
        for _ in range(3):
            result = self.tool.execute(request)
            results.append(result)
            assert result.status == "success"
        # All results should be consistent
        for result in results:
            path_instances = result.data["path_instances"]
            paths_04 = [p for p in path_instances if p["source"] == 0 and p["target"] == 4]
            assert len(paths_04) >= 1
            assert paths_04[0]["length"] == 4  # Consistent path length
    def test_large_graph_handling_real(self):
        """Test handling of reasonably large graphs"""
        # Create a larger test graph
        large_graph = nx.erdos_renyi_graph(50, 0.1)  # 50 nodes, 10% edge probability
        request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "networkx",
                "graph_data": {
                    "nodes": list(large_graph.nodes()),
                    "edges": list(large_graph.edges())
                },
                "analysis_type": "shortest_paths",
                "algorithms": ["bfs"],
                "performance_mode": "fast",
                "weighted": False
            },
            parameters={}
        )
        result = self.tool.execute(request)
        # Should succeed with larger graph
        assert result.status == "success"
        assert result.metadata["graph_size"] == 50
        assert result.metadata["batch_processed"] is False  # 50 nodes < 1000 threshold
    def test_zero_mocking_validation(self):
        """Validate that no mocking is used in this test suite"""
        # This test ensures we're using real implementations
        # Check that tool uses real NetworkX
        path_graph = self.test_graphs["path"]
        assert isinstance(path_graph, nx.Graph)
        assert hasattr(path_graph, 'nodes')
        assert hasattr(path_graph, 'edges')
        # Check that service manager is real
        assert hasattr(self.service_manager, 'identity_service')
        # Check that tool has real methods
        assert hasattr(self.tool, '_compute_dijkstra_paths')
        assert hasattr(self.tool, '_compute_bfs_paths')
        assert hasattr(self.tool, '_analyze_shortest_paths')
        assert hasattr(self.tool, '_analyze_flows')
        # Verify real NetworkX operations work
        shortest_path = nx.shortest_path(path_graph, 0, 4)
        assert shortest_path == [0, 1, 2, 3, 4]
        # Verify real numpy operations work
        test_array = np.array([1, 2, 3, 4, 5])
        assert np.mean(test_array) == 3.0
        print(" Zero mocking validation passed - all operations use real implementations")
# Additional integration-style tests
class TestT57PathAnalysisIntegration:
    """Integration tests for T57 with real research scenarios"""
    def setup_method(self):
        """Setup for integration tests"""
        self.service_manager = ServiceManager()
        self.tool = PathAnalysisTool(service_manager=self.service_manager)
    def test_academic_research_workflow_real(self):
        """Test complete academic research workflow"""
        # Create a research collaboration network
        research_graph = nx.Graph()
        # Add researchers and institutions
        researchers = [f"researcher_{i}" for i in range(20)]
        research_graph.add_nodes_from(researchers)
        # Add collaboration patterns
        collaborations = [
            # Dense collaboration cluster
            ("researcher_0", "researcher_1"), ("researcher_1", "researcher_2"),
            ("researcher_2", "researcher_3"), ("researcher_0", "researcher_3"),
            ("researcher_1", "researcher_3"),
            # Secondary cluster
            ("researcher_4", "researcher_5"), ("researcher_5", "researcher_6"),
            ("researcher_6", "researcher_7"), ("researcher_4", "researcher_7"),
            # Bridge connections
            ("researcher_2", "researcher_8"), ("researcher_8", "researcher_9"),
            ("researcher_6", "researcher_10"), ("researcher_10", "researcher_11"),
            # Isolated pairs
            ("researcher_12", "researcher_13"), ("researcher_14", "researcher_15"),
            # Cross-cluster bridges
            ("researcher_3", "researcher_12"), ("researcher_9", "researcher_16")
        ]
        research_graph.add_edges_from(collaborations)
        # Execute comprehensive path analysis
        request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "networkx",
                "graph_data": {
                    "nodes": list(research_graph.nodes()),
                    "edges": list(research_graph.edges())
                },
                "analysis_type": "comprehensive",
                "algorithms": ["dijkstra", "bfs"],
                "output_format": "detailed",
                "weighted": False
            },
            parameters={}
        )
        result = self.tool.execute(request)
        assert result.status == "success"
        # Verify comprehensive analysis
        assert "path_instances" in result.data
        assert "all_pairs_paths" in result.data
        assert "reachability_matrix" in result.data
        assert "path_stats" in result.data
        assert "algorithm_info" in result.data
        # Verify academic quality
        assert result.metadata["academic_ready"] is True
        assert result.metadata["publication_ready"] is True
        assert "statistical_significance" in result.metadata
        # Verify path diversity
        path_stats = result.data["path_stats"]
        assert path_stats["total_paths"] > 0
        assert path_stats["avg_path_length"] > 0
        # Verify reachability analysis
        reachability = result.data["reachability_matrix"]
        assert reachability["connectivity_ratio"] > 0
        print(f" Academic workflow completed: {path_stats['total_paths']} paths analyzed, {reachability['connectivity_ratio']:.3f} connectivity ratio")
    def test_publication_ready_output_real(self):
        """Test that output is ready for academic publication"""
        # Use a well-defined graph with known properties
        karate_graph = nx.karate_club_graph()  # Famous academic network
        request = ToolRequest(
            tool_id="T57_PATH_ANALYSIS",
            operation="analyze_paths",
            input_data={
                "graph_source": "networkx",
                "graph_data": {
                    "nodes": list(karate_graph.nodes()),
                    "edges": list(karate_graph.edges())
                },
                "analysis_type": "comprehensive",
                "algorithms": ["dijkstra", "bfs"],
                "output_format": "detailed",
                "weighted": False
            },
            parameters={}
        )
        result = self.tool.execute(request)
        assert result.status == "success"
        # Verify publication-ready elements
        data = result.data
        metadata = result.metadata
        # Algorithm reproducibility
        algorithm_info = data["algorithm_info"]
        assert "algorithms_used" in algorithm_info
        assert "execution_timestamp" in algorithm_info
        assert "graph_size" in algorithm_info
        assert "edge_count" in algorithm_info
        # Statistical validity
        path_stats = data["path_stats"]
        assert "total_paths" in path_stats
        assert "avg_path_length" in path_stats
        assert "connectivity_ratio" in path_stats
        # Academic metadata
        assert metadata["academic_ready"] is True
        assert metadata["publication_ready"] is True
        assert metadata["graph_size"] == len(karate_graph.nodes())
        assert metadata["edge_count"] == len(karate_graph.edges())
        # Performance metrics
        assert result.execution_time > 0
        assert result.memory_used >= 0
        print(f" Publication-ready analysis: {len(karate_graph.nodes())} nodes, {len(karate_graph.edges())} edges, {path_stats['total_paths']} paths")
if __name__ == "__main__":
    # Run specific test for quick validation
    test_suite = TestT57PathAnalysisUnified()
    test_suite.setup_method()
    print("Running T57 Path Analysis validation...")
    test_suite.test_tool_initialization()
    test_suite.test_dijkstra_shortest_paths_real()
    test_suite.test_bfs_shortest_paths_real()
    test_suite.test_zero_mocking_validation()
    print(" T57 Path Analysis tool validation passed!")
</file>

</files>
