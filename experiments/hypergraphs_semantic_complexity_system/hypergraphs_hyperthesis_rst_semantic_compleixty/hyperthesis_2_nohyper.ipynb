{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://claude.ai/chat/f44202b8-da19-4327-8821-49f24fdf26d7\n",
    "# https://tac.nist.gov/publications/2018/participant.papers/TAC2018.Hyperthesis.proceedings.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import networkx as nx\n",
    "import json\n",
    "\n",
    "\n",
    "class TextToNetwork:\n",
    "    def __init__(self, api_key):\n",
    "        \"\"\"Initialize the TextToNetwork converter with OpenAI API key.\"\"\"\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.graph = nx.DiGraph()\n",
    "\n",
    "    def _create_extraction_prompt(self, text):\n",
    "        \"\"\"Create a prompt that asks the LLM to extract entities and relationships.\"\"\"\n",
    "        return f\"\"\"Please analyze the following text and extract entities and their relationships. \n",
    "        Format your response as a JSON array of triples, where each triple is an object with \n",
    "        'subject', 'predicate', and 'object' fields. Extract only factual relationships that are \n",
    "        explicitly stated in the text.\n",
    "\n",
    "        Text: {text}\n",
    "\n",
    "        Respond only with the JSON array, e.g.:\n",
    "        [\n",
    "            {{\"subject\": \"John\", \"predicate\": \"works_at\", \"object\": \"Company\"}},\n",
    "            {{\"subject\": \"Company\", \"predicate\": \"located_in\", \"object\": \"New York\"}}\n",
    "        ]\n",
    "        \"\"\"\n",
    "\n",
    "    def extract_triples(self, text):\n",
    "        \"\"\"Extract subject-predicate-object triples from text using LLM.\"\"\"\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are a precise relationship extraction system.\",\n",
    "                    },\n",
    "                    {\"role\": \"user\", \"content\": self._create_extraction_prompt(text)},\n",
    "                ],\n",
    "                temperature=0,\n",
    "            )\n",
    "\n",
    "            # Parse the JSON response\n",
    "            triples = json.loads(response.choices[0].message.content)\n",
    "            return triples\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting triples: {e}\")\n",
    "            return []\n",
    "\n",
    "    def build_graph(self, text):\n",
    "        \"\"\"Build a NetworkX graph from the text.\"\"\"\n",
    "        # Clear existing graph\n",
    "        self.graph.clear()\n",
    "\n",
    "        # Extract triples and build graph\n",
    "        triples = self.extract_triples(text)\n",
    "\n",
    "        for triple in triples:\n",
    "            subject = triple[\"subject\"]\n",
    "            predicate = triple[\"predicate\"]\n",
    "            obj = triple[\"object\"]\n",
    "\n",
    "            # Add nodes if they don't exist\n",
    "            if not self.graph.has_node(subject):\n",
    "                self.graph.add_node(subject)\n",
    "            if not self.graph.has_node(obj):\n",
    "                self.graph.add_node(obj)\n",
    "\n",
    "            # Add edge with predicate as relationship type\n",
    "            self.graph.add_edge(subject, obj, relationship=predicate)\n",
    "\n",
    "        return self.graph\n",
    "\n",
    "    def get_graph_stats(self):\n",
    "        \"\"\"Return basic statistics about the graph.\"\"\"\n",
    "        return {\n",
    "            \"num_nodes\": self.graph.number_of_nodes(),\n",
    "            \"num_edges\": self.graph.number_of_edges(),\n",
    "            \"nodes\": list(self.graph.nodes()),\n",
    "            \"edges\": [\n",
    "                (u, v, d[\"relationship\"]) for u, v, d in self.graph.edges(data=True)\n",
    "            ],\n",
    "        }\n",
    "\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    api_key = \"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\"  # Replace with your actual API key\n",
    "    converter = TextToNetwork(api_key)\n",
    "\n",
    "    # Example text\n",
    "    text = \"\"\"\n",
    "    The Boeing 747 was designed by Joe Sutter. Boeing is headquartered in Chicago.\n",
    "    The aircraft entered service with Pan Am in 1970.\n",
    "    \"\"\"\n",
    "\n",
    "    # Build the graph\n",
    "    graph = converter.build_graph(text)\n",
    "\n",
    "    # Print statistics\n",
    "    stats = converter.get_graph_stats()\n",
    "    print(\"\\nGraph Statistics:\")\n",
    "    print(f\"Number of nodes: {stats['num_nodes']}\")\n",
    "    print(f\"Number of edges: {stats['num_edges']}\")\n",
    "    print(\"\\nNodes:\", stats[\"nodes\"])\n",
    "    print(\"\\nEdges (with relationships):\")\n",
    "    for edge in stats[\"edges\"]:\n",
    "        print(f\"{edge[0]} --[{edge[2]}]--> {edge[1]}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "import textwrap\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Claim:\n",
    "    id: str\n",
    "    type: str  # 'Direct' or 'Inference'\n",
    "    content: str\n",
    "    supports: List[str] = None\n",
    "    contradicts: List[str] = None\n",
    "    infers_from: List[str] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.supports = self.supports or []\n",
    "        self.contradicts = self.contradicts or []\n",
    "        self.infers_from = self.infers_from or []\n",
    "\n",
    "\n",
    "def create_claim_network():\n",
    "    # Create claims\n",
    "    claims = {\n",
    "        \"D1\": Claim(\"D1\", \"Direct\", \"Elon Musk is ranked #19 on Diablo 4 leaderboard\"),\n",
    "        \"D2\": Claim(\"D2\", \"Direct\", \"The leaderboard has 873 submissions total\"),\n",
    "        \"D3\": Claim(\"D3\", \"Direct\", \"It takes 120-150 hours to reach claimed level\"),\n",
    "        \"D4\": Claim(\"D4\", \"Direct\", \"He's at Paragon level 299\"),\n",
    "        \"D5\": Claim(\n",
    "            \"D5\", \"Direct\", \"His Steam account shows this ranking\", supports=[\"D1\"]\n",
    "        ),\n",
    "        \"I1\": Claim(\n",
    "            \"I1\",\n",
    "            \"Inference\",\n",
    "            \"He must have a team playing for him\",\n",
    "            infers_from=[\"D3\", \"D4\"],\n",
    "            contradicts=[\"D1\"],\n",
    "        ),\n",
    "        \"I2\": Claim(\n",
    "            \"I2\",\n",
    "            \"Inference\",\n",
    "            \"He can play during his private jet flights\",\n",
    "            supports=[\"D1\"],\n",
    "            contradicts=[\"I1\"],\n",
    "        ),\n",
    "        \"I3\": Claim(\n",
    "            \"I3\",\n",
    "            \"Inference\",\n",
    "            \"The ranking isn't meaningful because it's a bugged build\",\n",
    "            contradicts=[\"D1\"],\n",
    "        ),\n",
    "    }\n",
    "    return claims\n",
    "\n",
    "\n",
    "def wrap_text(text, width=20):\n",
    "    \"\"\"Wrap text to specified width.\"\"\"\n",
    "    return \"\\n\".join(textwrap.wrap(text, width=width))\n",
    "\n",
    "\n",
    "def visualize_claim_network(claims):\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add nodes with wrapped content\n",
    "    for claim_id, claim in claims.items():\n",
    "        G.add_node(claim_id, type=claim.type, content=wrap_text(claim.content))\n",
    "\n",
    "    # Add edges\n",
    "    edge_colors = []\n",
    "    edge_styles = []\n",
    "    edges = []\n",
    "\n",
    "    for claim_id, claim in claims.items():\n",
    "        # Add support edges\n",
    "        for supported in claim.supports:\n",
    "            edges.append((claim_id, supported))\n",
    "            edge_colors.append(\"green\")\n",
    "            edge_styles.append(\"solid\")\n",
    "\n",
    "        # Add contradiction edges\n",
    "        for contradicted in claim.contradicts:\n",
    "            edges.append((claim_id, contradicted))\n",
    "            edge_colors.append(\"red\")\n",
    "            edge_styles.append(\"dashed\")\n",
    "\n",
    "        # Add inference edges\n",
    "        for inferred_from in claim.infers_from:\n",
    "            edges.append((inferred_from, claim_id))\n",
    "            edge_colors.append(\"blue\")\n",
    "            edge_styles.append(\"dotted\")\n",
    "\n",
    "    # Set up the plot\n",
    "    plt.figure(figsize=(20, 15))\n",
    "\n",
    "    # Create layout with more spacing\n",
    "    pos = nx.spring_layout(G, k=2, iterations=50)\n",
    "\n",
    "    # Draw nodes\n",
    "    direct_nodes = [n for n, attr in G.nodes(data=True) if attr[\"type\"] == \"Direct\"]\n",
    "    inference_nodes = [\n",
    "        n for n, attr in G.nodes(data=True) if attr[\"type\"] == \"Inference\"\n",
    "    ]\n",
    "\n",
    "    # Draw nodes\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos, nodelist=direct_nodes, node_color=\"lightblue\", node_size=3000, alpha=0.7\n",
    "    )\n",
    "    nx.draw_networkx_nodes(\n",
    "        G,\n",
    "        pos,\n",
    "        nodelist=inference_nodes,\n",
    "        node_color=\"lightgreen\",\n",
    "        node_size=3000,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "    # Draw edges\n",
    "    for (u, v), color, style in zip(edges, edge_colors, edge_styles):\n",
    "        nx.draw_networkx_edges(\n",
    "            G,\n",
    "            pos,\n",
    "            edgelist=[(u, v)],\n",
    "            edge_color=color,\n",
    "            style=style,\n",
    "            arrows=True,\n",
    "            arrowsize=20,\n",
    "        )\n",
    "\n",
    "    # Add node labels with wrapped content\n",
    "    labels = {node: f\"{node}\\n{attr['content']}\" for node, attr in G.nodes(data=True)}\n",
    "    nx.draw_networkx_labels(G, pos, labels, font_size=8)\n",
    "\n",
    "    # Create legend\n",
    "    legend_elements = [\n",
    "        plt.Line2D([0], [0], color=\"green\", label=\"Supports\"),\n",
    "        plt.Line2D([0], [0], color=\"red\", linestyle=\"--\", label=\"Contradicts\"),\n",
    "        plt.Line2D([0], [0], color=\"blue\", linestyle=\":\", label=\"Infers From\"),\n",
    "        plt.Rectangle((0, 0), 1, 1, fc=\"lightblue\", alpha=0.7, label=\"Direct Claim\"),\n",
    "        plt.Rectangle((0, 0), 1, 1, fc=\"lightgreen\", alpha=0.7, label=\"Inference\"),\n",
    "    ]\n",
    "\n",
    "    plt.legend(handles=legend_elements, loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.title(\"Claim Network Analysis\", pad=20)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Adjust layout to prevent text overlap\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "\n",
    "\n",
    "def main():\n",
    "    claims = create_claim_network()\n",
    "    plt = visualize_claim_network(claims)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Set\n",
    "import textwrap\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Claim:\n",
    "    id: str\n",
    "    type: str  # 'Direct' or 'Inference'\n",
    "    content: str\n",
    "    supports: List[str] = None\n",
    "    contradicts: List[str] = None\n",
    "    infers_from: List[str] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.supports = self.supports or []\n",
    "        self.contradicts = self.contradicts or []\n",
    "        self.infers_from = self.infers_from or []\n",
    "\n",
    "\n",
    "def get_inference_hierarchy(claims: Dict[str, Claim]) -> Dict[str, Set[str]]:\n",
    "    \"\"\"Calculate the full support hierarchy for each inference.\"\"\"\n",
    "    hierarchy = defaultdict(set)\n",
    "\n",
    "    def get_support_chain(claim_id: str, visited: Set[str] = None) -> Set[str]:\n",
    "        if visited is None:\n",
    "            visited = set()\n",
    "        if claim_id in visited:\n",
    "            return set()\n",
    "\n",
    "        visited.add(claim_id)\n",
    "        claim = claims[claim_id]\n",
    "        supports = set()\n",
    "\n",
    "        # Add direct inference sources\n",
    "        if claim.infers_from:\n",
    "            supports.update(claim.infers_from)\n",
    "            # Recursively get their support chains\n",
    "            for source in claim.infers_from:\n",
    "                supports.update(get_support_chain(source, visited))\n",
    "\n",
    "        return supports\n",
    "\n",
    "    # Calculate for each inference claim\n",
    "    for claim_id, claim in claims.items():\n",
    "        if claim.type == \"Inference\":\n",
    "            hierarchy[claim_id] = get_support_chain(claim_id)\n",
    "\n",
    "    return hierarchy\n",
    "\n",
    "\n",
    "def create_claim_network():\n",
    "    claims = {\n",
    "        \"D1\": Claim(\"D1\", \"Direct\", \"Elon Musk is ranked #19 on Diablo 4 leaderboard\"),\n",
    "        \"D2\": Claim(\"D2\", \"Direct\", \"The leaderboard has 873 submissions total\"),\n",
    "        \"D3\": Claim(\"D3\", \"Direct\", \"It takes 120-150 hours to reach claimed level\"),\n",
    "        \"D4\": Claim(\"D4\", \"Direct\", \"He's at Paragon level 299\"),\n",
    "        \"D5\": Claim(\n",
    "            \"D5\", \"Direct\", \"His Steam account shows this ranking\", supports=[\"D1\"]\n",
    "        ),\n",
    "        \"I1\": Claim(\n",
    "            \"I1\",\n",
    "            \"Inference\",\n",
    "            \"He must have a team playing for him\",\n",
    "            infers_from=[\"D3\", \"D4\"],\n",
    "            contradicts=[\"D1\"],\n",
    "        ),\n",
    "        \"I2\": Claim(\n",
    "            \"I2\",\n",
    "            \"Inference\",\n",
    "            \"He can play during his private jet flights\",\n",
    "            supports=[\"D1\"],\n",
    "            contradicts=[\"I1\"],\n",
    "        ),\n",
    "        \"I3\": Claim(\n",
    "            \"I3\",\n",
    "            \"Inference\",\n",
    "            \"The ranking isn't meaningful because it's a bugged build\",\n",
    "            contradicts=[\"D1\"],\n",
    "        ),\n",
    "    }\n",
    "    return claims\n",
    "\n",
    "\n",
    "def wrap_text(text, width=20):\n",
    "    return \"\\n\".join(textwrap.wrap(text, width=width))\n",
    "\n",
    "\n",
    "def visualize_claim_network(claims):\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Calculate inference hierarchies\n",
    "    hierarchies = get_inference_hierarchy(claims)\n",
    "\n",
    "    # Add nodes with wrapped content and hierarchy info\n",
    "    for claim_id, claim in claims.items():\n",
    "        content = claim.content\n",
    "        if claim.type == \"Inference\":\n",
    "            support_chain = hierarchies[claim_id]\n",
    "            if support_chain:\n",
    "                content += f\"\\nSupported by: {', '.join(sorted(support_chain))}\"\n",
    "\n",
    "        G.add_node(claim_id, type=claim.type, content=wrap_text(content))\n",
    "\n",
    "    # Edge information with labels\n",
    "    edges = []\n",
    "    edge_colors = []\n",
    "    edge_styles = []\n",
    "    edge_labels = {}\n",
    "\n",
    "    for claim_id, claim in claims.items():\n",
    "        # Support edges\n",
    "        for supported in claim.supports:\n",
    "            edges.append((claim_id, supported))\n",
    "            edge_colors.append(\"green\")\n",
    "            edge_styles.append(\"solid\")\n",
    "            edge_labels[(claim_id, supported)] = \"supports\"\n",
    "\n",
    "        # Contradiction edges\n",
    "        for contradicted in claim.contradicts:\n",
    "            edges.append((claim_id, contradicted))\n",
    "            edge_colors.append(\"red\")\n",
    "            edge_styles.append(\"dashed\")\n",
    "            edge_labels[(claim_id, contradicted)] = \"contradicts\"\n",
    "\n",
    "        # Inference edges\n",
    "        for inferred_from in claim.infers_from:\n",
    "            edges.append((inferred_from, claim_id))\n",
    "            edge_colors.append(\"blue\")\n",
    "            edge_styles.append(\"dotted\")\n",
    "            edge_labels[(inferred_from, claim_id)] = \"infers from\"\n",
    "\n",
    "    plt.figure(figsize=(20, 15))\n",
    "\n",
    "    # Create layout with more spacing\n",
    "    pos = nx.spring_layout(G, k=2, iterations=50)\n",
    "\n",
    "    # Draw nodes\n",
    "    direct_nodes = [n for n, attr in G.nodes(data=True) if attr[\"type\"] == \"Direct\"]\n",
    "    inference_nodes = [\n",
    "        n for n, attr in G.nodes(data=True) if attr[\"type\"] == \"Inference\"\n",
    "    ]\n",
    "\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos, nodelist=direct_nodes, node_color=\"lightblue\", node_size=4000, alpha=0.7\n",
    "    )\n",
    "    nx.draw_networkx_nodes(\n",
    "        G,\n",
    "        pos,\n",
    "        nodelist=inference_nodes,\n",
    "        node_color=\"lightgreen\",\n",
    "        node_size=4000,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "    # Draw edges with labels\n",
    "    for (u, v), color, style in zip(edges, edge_colors, edge_styles):\n",
    "        nx.draw_networkx_edges(\n",
    "            G,\n",
    "            pos,\n",
    "            edgelist=[(u, v)],\n",
    "            edge_color=color,\n",
    "            style=style,\n",
    "            arrows=True,\n",
    "            arrowsize=20,\n",
    "        )\n",
    "\n",
    "    # Add edge labels\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
    "\n",
    "    # Add node labels with wrapped content\n",
    "    labels = {node: f\"{node}\\n{attr['content']}\" for node, attr in G.nodes(data=True)}\n",
    "    nx.draw_networkx_labels(G, pos, labels, font_size=8)\n",
    "\n",
    "    # Create legend\n",
    "    legend_elements = [\n",
    "        plt.Line2D([0], [0], color=\"green\", label=\"Supports\"),\n",
    "        plt.Line2D([0], [0], color=\"red\", linestyle=\"--\", label=\"Contradicts\"),\n",
    "        plt.Line2D([0], [0], color=\"blue\", linestyle=\":\", label=\"Infers From\"),\n",
    "        plt.Rectangle((0, 0), 1, 1, fc=\"lightblue\", alpha=0.7, label=\"Direct Claim\"),\n",
    "        plt.Rectangle((0, 0), 1, 1, fc=\"lightgreen\", alpha=0.7, label=\"Inference\"),\n",
    "    ]\n",
    "\n",
    "    plt.legend(handles=legend_elements, loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.title(\"Claim Network Analysis\", pad=20)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "\n",
    "\n",
    "def main():\n",
    "    claims = create_claim_network()\n",
    "    plt = visualize_claim_network(claims)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Dict\n",
    "import textwrap\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RedditClaim:\n",
    "    id: str\n",
    "    content: str\n",
    "    supports: List[str] = None  # IDs of claims this supports\n",
    "    author: str = \"\"\n",
    "    score: int = 0\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.supports = self.supports or []\n",
    "\n",
    "\n",
    "def create_sample_network():\n",
    "    # Create nodes for the key claims and arguments\n",
    "    claims = {\n",
    "        # Original claim\n",
    "        \"C1\": RedditClaim(\n",
    "            \"C1\", \"Elon Musk is in top 20 on Diablo 4 leaderboard\", author=\"Fit-Ad-5946\"\n",
    "        ),\n",
    "        # Supporting evidence\n",
    "        \"C2\": RedditClaim(\n",
    "            \"C2\", \"He is ranked #19 on helltides.com/pit\", author=\"5HAGNA5TY\"\n",
    "        ),\n",
    "        \"C3\": RedditClaim(\n",
    "            \"C3\", \"The leaderboard has 873 submissions total\", author=\"No-Service-3987\"\n",
    "        ),\n",
    "        # Inference with supporting claims\n",
    "        \"C4\": RedditClaim(\n",
    "            \"C4\", \"Must have team playing for him\", supports=[\"C1\"], author=\"Stalltt\"\n",
    "        ),\n",
    "        \"C5\": RedditClaim(\n",
    "            \"C5\", \"Running multiple companies\", supports=[\"C4\"], author=\"Stalltt\"\n",
    "        ),\n",
    "        \"C6\": RedditClaim(\n",
    "            \"C6\",\n",
    "            \"Takes 120-150 hours gameplay time\",\n",
    "            supports=[\"C4\"],\n",
    "            author=\"jarret_o\",\n",
    "        ),\n",
    "        # Counter argument\n",
    "        \"C7\": RedditClaim(\n",
    "            \"C7\",\n",
    "            \"Can play during private jet flights\",\n",
    "            supports=[\"C1\"],\n",
    "            author=\"Standard-Pin1207\",\n",
    "        ),\n",
    "        # Technical context\n",
    "        \"C8\": RedditClaim(\n",
    "            \"C8\",\n",
    "            \"Using Spiritborn build (currently bugged/overpowered)\",\n",
    "            author=\"Normal-Ad-204\",\n",
    "        ),\n",
    "    }\n",
    "    return claims\n",
    "\n",
    "\n",
    "def visualize_claim_network(claims: Dict[str, RedditClaim]):\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add nodes\n",
    "    for claim_id, claim in claims.items():\n",
    "        label = (\n",
    "            f\"{claim_id}\\n{textwrap.fill(claim.content, width=30)}\\n- {claim.author}\"\n",
    "        )\n",
    "        G.add_node(claim_id, label=label)\n",
    "\n",
    "        # Add support edges\n",
    "        for supported_id in claim.supports:\n",
    "            G.add_edge(claim_id, supported_id)\n",
    "\n",
    "    # Set up visualization\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    pos = nx.spring_layout(G, k=2, iterations=50)\n",
    "\n",
    "    # Draw nodes\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=\"lightblue\", node_size=3000, alpha=0.7)\n",
    "\n",
    "    # Draw edges with arrows\n",
    "    nx.draw_networkx_edges(G, pos, edge_color=\"gray\", arrows=True, arrowsize=20)\n",
    "\n",
    "    # Add node labels\n",
    "    labels = nx.get_node_attributes(G, \"label\")\n",
    "    nx.draw_networkx_labels(G, pos, labels, font_size=8)\n",
    "\n",
    "    # Add edge labels\n",
    "    edge_labels = {(u, v): \"supports\" for (u, v) in G.edges()}\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
    "\n",
    "    plt.title(\"Reddit Claim Network\", pad=20)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "\n",
    "\n",
    "def main():\n",
    "    claims = create_sample_network()\n",
    "    plt = visualize_claim_network(claims)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional\n",
    "import textwrap\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "# API key setup\n",
    "openai_api_key = \"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\"\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RedditClaim:\n",
    "    id: str\n",
    "    content: str\n",
    "    justified_by: List[str] = None\n",
    "    author: str = \"\"\n",
    "    score: int = 0\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.justified_by = self.justified_by or []\n",
    "\n",
    "\n",
    "def chunk_comments(text: str) -> List[Dict]:\n",
    "    \"\"\"Split text into individual comments.\"\"\"\n",
    "    pattern = r\"(?P<author>[\\w-]+)\\s+•\\s+(?P<time>\\d+d ago)\\s+•\\s*(?P<content>.*?)(?=\\n\\nUpvote|\\Z)\"\n",
    "\n",
    "    comments = []\n",
    "    for match in re.finditer(pattern, text, re.DOTALL):\n",
    "        comment = {\n",
    "            \"author\": match.group(\"author\"),\n",
    "            \"content\": match.group(\"content\").strip(),\n",
    "            \"time\": match.group(\"time\"),\n",
    "        }\n",
    "        comments.append(comment)\n",
    "    return comments\n",
    "\n",
    "\n",
    "def analyze_comment(comment: Dict) -> List[Dict]:\n",
    "    \"\"\"Use LLM to analyze comment for claims and justifications.\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"Analyze this Reddit comment for claims and their justifications.\n",
    "    If the comment contains no clear claims or is just expressing agreement/disagreement without substance, return \"PASS\".\n",
    "    If it contains claims, return a JSON array of claim objects.\n",
    "    Each claim object should have:\n",
    "    - \"claim\": The main assertion\n",
    "    - \"justified_by\": Array of statements that justify this claim (empty if none)\n",
    "\n",
    "    Comment by {comment['author']}: {comment['content']}\n",
    "\n",
    "    Return either \"PASS\" or a JSON array like:\n",
    "    [\n",
    "        {{\n",
    "            \"claim\": \"X is true\",\n",
    "            \"justified_by\": [\"because of Y\", \"because of Z\"]\n",
    "        }}\n",
    "    ]\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a claim analysis assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "        result = response.choices[0].message.content.strip()\n",
    "\n",
    "        # More robust PASS checking\n",
    "        if \"PASS\" in result.upper() or result.isspace() or not result:\n",
    "            return []\n",
    "\n",
    "        try:\n",
    "            return json.loads(result)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Failed to parse JSON for comment by {comment['author']}: {result}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing comment by {comment['author']}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def build_claim_network(comments: List[Dict]) -> Dict[str, RedditClaim]:\n",
    "    \"\"\"Build network of claims from comments.\"\"\"\n",
    "    claim_id_counter = 1\n",
    "    claims = {}\n",
    "\n",
    "    for comment in comments:\n",
    "        analyzed_claims = analyze_comment(comment)\n",
    "\n",
    "        for claim_data in analyzed_claims:\n",
    "            # Create main claim node\n",
    "            main_id = f\"C{claim_id_counter}\"\n",
    "            claim_id_counter += 1\n",
    "\n",
    "            # Create nodes for justifications\n",
    "            justification_ids = []\n",
    "            for justification in claim_data.get(\"justified_by\", []):\n",
    "                just_id = f\"C{claim_id_counter}\"\n",
    "                claim_id_counter += 1\n",
    "                claims[just_id] = RedditClaim(\n",
    "                    id=just_id, content=justification, author=comment[\"author\"]\n",
    "                )\n",
    "                justification_ids.append(just_id)\n",
    "\n",
    "            # Add main claim with justifications\n",
    "            claims[main_id] = RedditClaim(\n",
    "                id=main_id,\n",
    "                content=claim_data[\"claim\"],\n",
    "                justified_by=justification_ids,\n",
    "                author=comment[\"author\"],\n",
    "            )\n",
    "\n",
    "    return claims\n",
    "\n",
    "\n",
    "def visualize_claim_network(claims: Dict[str, RedditClaim]):\n",
    "    \"\"\"Create visualization of claim network.\"\"\"\n",
    "    if not claims:\n",
    "        print(\"No claims to visualize\")\n",
    "        return None\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add nodes\n",
    "    for claim_id, claim in claims.items():\n",
    "        label = (\n",
    "            f\"{claim_id}\\n{textwrap.fill(claim.content, width=30)}\\n- {claim.author}\"\n",
    "        )\n",
    "        G.add_node(claim_id, label=label)\n",
    "\n",
    "        # Add justification edges\n",
    "        for justified_by_id in claim.justified_by:\n",
    "            G.add_edge(justified_by_id, claim_id)\n",
    "\n",
    "    # Set up visualization\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    pos = nx.spring_layout(G, k=2, iterations=50)\n",
    "\n",
    "    # Draw nodes\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=\"lightblue\", node_size=3000, alpha=0.7)\n",
    "\n",
    "    # Draw edges with arrows\n",
    "    nx.draw_networkx_edges(G, pos, edge_color=\"gray\", arrows=True, arrowsize=20)\n",
    "\n",
    "    # Add node labels\n",
    "    labels = nx.get_node_attributes(G, \"label\")\n",
    "    nx.draw_networkx_labels(G, pos, labels, font_size=8)\n",
    "\n",
    "    # Add edge labels\n",
    "    edge_labels = {(u, v): \"justifies\" for (u, v) in G.edges()}\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
    "\n",
    "    plt.title(\"Reddit Claim Network\", pad=20)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Read Reddit text\n",
    "    with open(r\"C:\\Users\\bmills\\Documents\\reddit_test.txt\", \"r\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # Process the text\n",
    "    comments = chunk_comments(text)\n",
    "    claims = build_claim_network(comments)\n",
    "\n",
    "    # Visualize\n",
    "    plt = visualize_claim_network(claims)\n",
    "    if plt:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS IS CHANGING IT UP A LITTLE\n",
    "https://claude.ai/chat/1054436b-8338-4ba5-b4fb-388bf81d7b0a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add hypothesis nodes\n",
    "hypotheses = [\"temple\", \"market\"]\n",
    "evidence = [\"altar\", \"artifacts\", \"storage\", \"coins\", \"courtyard\"]\n",
    "\n",
    "# Add nodes with different colors for hypotheses and evidence\n",
    "for h in hypotheses:\n",
    "    G.add_node(h, type=\"hypothesis\")\n",
    "for e in evidence:\n",
    "    G.add_node(e, type=\"evidence\")\n",
    "\n",
    "# Add edges with probabilities\n",
    "edges = [\n",
    "    (\"temple\", \"altar\", 0.9),\n",
    "    (\"temple\", \"artifacts\", 0.8),\n",
    "    (\"temple\", \"storage\", 0.3),\n",
    "    (\"temple\", \"coins\", 0.2),\n",
    "    (\"temple\", \"courtyard\", 0.5),\n",
    "    (\"market\", \"altar\", 0.1),\n",
    "    (\"market\", \"artifacts\", 0.2),\n",
    "    (\"market\", \"storage\", 0.9),\n",
    "    (\"market\", \"coins\", 0.8),\n",
    "    (\"market\", \"courtyard\", 0.5),\n",
    "]\n",
    "\n",
    "# Add edges with their probabilities\n",
    "for h, e, p in edges:\n",
    "    G.add_edge(h, e, probability=p)\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create layout\n",
    "pos = nx.spring_layout(G, k=1, iterations=50)\n",
    "\n",
    "# Draw nodes\n",
    "node_colors = [\n",
    "    \"lightblue\" if G.nodes[node][\"type\"] == \"hypothesis\" else \"lightgreen\"\n",
    "    for node in G.nodes()\n",
    "]\n",
    "nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=2000)\n",
    "\n",
    "# Draw edges\n",
    "nx.draw_networkx_edges(G, pos)\n",
    "\n",
    "# Draw labels\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "# Draw edge labels (probabilities)\n",
    "edge_labels = nx.get_edge_attributes(G, \"probability\")\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels)\n",
    "\n",
    "plt.title(\"Archaeological Site Hypothesis Network\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Physical Features (lowest level)\n",
    "physical_features = [\n",
    "    \"stone_altar\",\n",
    "    \"stone_basin\",\n",
    "    \"columns\",  # ritual features\n",
    "    \"storage_rooms\",\n",
    "    \"loading_area\",\n",
    "    \"counters\",  # commercial features\n",
    "    \"enclosed_walls\",\n",
    "    \"central_courtyard\",\n",
    "    \"drainage\",  # general features\n",
    "]\n",
    "\n",
    "# Mid-level interpretations\n",
    "interpretations = {\n",
    "    \"ritual_space\": [\"stone_altar\", \"stone_basin\", \"columns\"],\n",
    "    \"commercial_space\": [\"storage_rooms\", \"loading_area\", \"counters\"],\n",
    "    \"public_gathering\": [\"central_courtyard\", \"enclosed_walls\", \"drainage\"],\n",
    "}\n",
    "\n",
    "# Artifacts found (another low level)\n",
    "artifacts = {\n",
    "    \"ritual_items\": [\"figurines\", \"incense_burners\", \"offering_bowls\"],\n",
    "    \"trade_items\": [\"coins\", \"weights\", \"storage_jars\"],\n",
    "}\n",
    "\n",
    "# High-level hypotheses\n",
    "site_functions = {\n",
    "    \"temple_complex\": [\"ritual_space\", \"public_gathering\", \"ritual_items\"],\n",
    "    \"market_complex\": [\"commercial_space\", \"public_gathering\", \"trade_items\"],\n",
    "}\n",
    "\n",
    "# Add nodes with hierarchical levels\n",
    "for feature in physical_features:\n",
    "    G.add_node(feature, level=0, type=\"physical\")\n",
    "\n",
    "for artifact_category, items in artifacts.items():\n",
    "    for item in items:\n",
    "        G.add_node(item, level=0, type=\"artifact\")\n",
    "    G.add_node(artifact_category, level=1, type=\"artifact_category\")\n",
    "    for item in items:\n",
    "        G.add_edge(item, artifact_category, weight=1)\n",
    "\n",
    "for interp, features in interpretations.items():\n",
    "    G.add_node(interp, level=2, type=\"interpretation\")\n",
    "    for feature in features:\n",
    "        G.add_edge(feature, interp, weight=1)\n",
    "\n",
    "for function, components in site_functions.items():\n",
    "    G.add_node(function, level=3, type=\"hypothesis\")\n",
    "    for component in components:\n",
    "        G.add_edge(component, function, weight=1)\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Create hierarchical layout\n",
    "pos = nx.spring_layout(G)  # Initialize with spring layout\n",
    "# Adjust y-coordinates based on level\n",
    "for node in G.nodes():\n",
    "    level = G.nodes[node][\"level\"]\n",
    "    pos[node] = np.array([pos[node][0], 0.25 * level])\n",
    "\n",
    "# Draw nodes with different colors per level\n",
    "colors = [\"lightgray\", \"lightgreen\", \"lightblue\", \"pink\"]\n",
    "for level in range(4):\n",
    "    nodes_at_level = [node for node in G.nodes() if G.nodes[node][\"level\"] == level]\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos, nodelist=nodes_at_level, node_color=colors[level], node_size=2000\n",
    "    )\n",
    "\n",
    "# Draw edges\n",
    "nx.draw_networkx_edges(G, pos)\n",
    "\n",
    "# Draw labels with smaller font\n",
    "nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "\n",
    "plt.title(\"Hierarchical Archaeological Site Analysis\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the levels for clarity\n",
    "print(\"\\nHierarchical Structure:\")\n",
    "for level in range(4):\n",
    "    print(f\"\\nLevel {level}:\")\n",
    "    nodes = [node for node in G.nodes() if G.nodes[node][\"level\"] == level]\n",
    "    for node in nodes:\n",
    "        print(f\"- {node} ({G.nodes[node]['type']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Raw Evidence/Claims from social media (Level 0)\n",
    "evidence = {\n",
    "    \"visual_evidence\": [\n",
    "        \"navy_footage_2004\",\n",
    "        \"phoenix_lights_1997\",\n",
    "        \"cell_phone_videos\",\n",
    "        \"radar_data\",\n",
    "    ],\n",
    "    \"testimonies\": [\n",
    "        \"pilot_reports\",\n",
    "        \"military_personnel\",\n",
    "        \"civilian_witnesses\",\n",
    "        \"government_officials\",\n",
    "    ],\n",
    "    \"official_documents\": [\n",
    "        \"pentagon_report_2021\",\n",
    "        \"project_bluebook\",\n",
    "        \"declassified_files\",\n",
    "        \"nasa_statements\",\n",
    "    ],\n",
    "    \"counter_evidence\": [\n",
    "        \"debunked_photos\",\n",
    "        \"hoax_confessions\",\n",
    "        \"weather_phenomena\",\n",
    "        \"camera_artifacts\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Mid-level interpretations (Level 1)\n",
    "interpretations = {\n",
    "    \"credible_observations\": [\n",
    "        \"navy_footage_2004\",\n",
    "        \"radar_data\",\n",
    "        \"pilot_reports\",\n",
    "        \"military_personnel\",\n",
    "    ],\n",
    "    \"government_acknowledgment\": [\n",
    "        \"pentagon_report_2021\",\n",
    "        \"nasa_statements\",\n",
    "        \"government_officials\",\n",
    "    ],\n",
    "    \"explainable_cases\": [\"debunked_photos\", \"hoax_confessions\", \"weather_phenomena\"],\n",
    "    \"mass_sightings\": [\"phoenix_lights_1997\", \"civilian_witnesses\"],\n",
    "    \"historical_record\": [\"project_bluebook\", \"declassified_files\"],\n",
    "}\n",
    "\n",
    "# Arguments (Level 2)\n",
    "arguments = {\n",
    "    \"evidence_for_ufo\": [\n",
    "        \"credible_observations\",\n",
    "        \"government_acknowledgment\",\n",
    "        \"mass_sightings\",\n",
    "    ],\n",
    "    \"evidence_against_ufo\": [\n",
    "        \"explainable_cases\",\n",
    "        \"camera_artifacts\",\n",
    "        \"historical_record\",  # could support either side\n",
    "    ],\n",
    "}\n",
    "\n",
    "# High-level conclusions (Level 3)\n",
    "conclusions = {\n",
    "    \"ufos_are_real\": [\"evidence_for_ufo\"],\n",
    "    \"ufos_are_explainable\": [\"evidence_against_ufo\"],\n",
    "}\n",
    "\n",
    "# Add nodes with levels\n",
    "# Level 0: Raw Evidence\n",
    "for category, items in evidence.items():\n",
    "    for item in items:\n",
    "        G.add_node(item, level=0, type=\"evidence\")\n",
    "\n",
    "# Level 1: Interpretations\n",
    "for interp, items in interpretations.items():\n",
    "    G.add_node(interp, level=1, type=\"interpretation\")\n",
    "    for item in items:\n",
    "        G.add_edge(item, interp)\n",
    "\n",
    "# Level 2: Arguments\n",
    "for arg, items in arguments.items():\n",
    "    G.add_node(arg, level=2, type=\"argument\")\n",
    "    for item in items:\n",
    "        G.add_edge(item, arg)\n",
    "\n",
    "# Level 3: Conclusions\n",
    "for concl, items in conclusions.items():\n",
    "    G.add_node(concl, level=3, type=\"conclusion\")\n",
    "    for item in items:\n",
    "        G.add_edge(item, concl)\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "# Create hierarchical layout\n",
    "pos = nx.spring_layout(G, k=1, iterations=50)\n",
    "for node in G.nodes():\n",
    "    level = G.nodes[node][\"level\"]\n",
    "    pos[node] = np.array([pos[node][0], level / 2])  # Adjust vertical spacing\n",
    "\n",
    "# Draw nodes with different colors per level\n",
    "colors = [\"lightgray\", \"lightgreen\", \"lightblue\", \"pink\"]\n",
    "for level in range(4):\n",
    "    nodes_at_level = [node for node in G.nodes() if G.nodes[node][\"level\"] == level]\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos, nodelist=nodes_at_level, node_color=colors[level], node_size=2000\n",
    "    )\n",
    "\n",
    "# Draw edges\n",
    "nx.draw_networkx_edges(G, pos)\n",
    "\n",
    "# Draw labels\n",
    "nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "\n",
    "plt.title(\"UFO Social Media Argument Network\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print structure\n",
    "print(\"\\nNetwork Structure:\")\n",
    "for level in range(4):\n",
    "    print(f\"\\nLevel {level}:\")\n",
    "    nodes = [node for node in G.nodes() if G.nodes[node][\"level\"] == level]\n",
    "    for node in nodes:\n",
    "        print(f\"- {node} ({G.nodes[node]['type']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "class HierarchicalBayesianNetwork:\n",
    "    def __init__(self):\n",
    "        # Initialize network structure\n",
    "        self.G = nx.DiGraph()\n",
    "\n",
    "        # Level 1: Hyperpriors (population level)\n",
    "        self.G.add_node(\n",
    "            \"mu_population\",\n",
    "            level=1,\n",
    "            distribution=\"normal\",\n",
    "            params={\"mu\": 0, \"sigma\": 1},\n",
    "        )\n",
    "\n",
    "        self.G.add_node(\n",
    "            \"sigma_population\",\n",
    "            level=1,\n",
    "            distribution=\"gamma\",\n",
    "            params={\"alpha\": 2, \"beta\": 1},\n",
    "        )\n",
    "\n",
    "        # Level 2: Group-level parameters\n",
    "        groups = [\"group_A\", \"group_B\", \"group_C\"]\n",
    "        for group in groups:\n",
    "            self.G.add_node(\n",
    "                f\"mu_{group}\",\n",
    "                level=2,\n",
    "                distribution=\"normal\",\n",
    "                params={\"mu\": \"mu_population\", \"sigma\": \"sigma_population\"},\n",
    "            )\n",
    "\n",
    "            self.G.add_node(\n",
    "                f\"sigma_{group}\",\n",
    "                level=2,\n",
    "                distribution=\"gamma\",\n",
    "                params={\"alpha\": 2, \"beta\": 1},\n",
    "            )\n",
    "\n",
    "            # Add edges from population parameters\n",
    "            self.G.add_edge(\"mu_population\", f\"mu_{group}\")\n",
    "            self.G.add_edge(\"sigma_population\", f\"mu_{group}\")\n",
    "\n",
    "        # Level 3: Individual observations\n",
    "        for group in groups:\n",
    "            for i in range(3):  # 3 observations per group\n",
    "                obs_node = f\"obs_{group}_{i}\"\n",
    "                self.G.add_node(\n",
    "                    obs_node,\n",
    "                    level=3,\n",
    "                    distribution=\"normal\",\n",
    "                    params={\"mu\": f\"mu_{group}\", \"sigma\": f\"sigma_{group}\"},\n",
    "                )\n",
    "\n",
    "                # Add edges from group parameters\n",
    "                self.G.add_edge(f\"mu_{group}\", obs_node)\n",
    "                self.G.add_edge(f\"sigma_{group}\", obs_node)\n",
    "\n",
    "    def visualize(self):\n",
    "        plt.figure(figsize=(12, 8))\n",
    "\n",
    "        # Create hierarchical layout\n",
    "        pos = nx.spring_layout(self.G, k=1, iterations=50)\n",
    "\n",
    "        # Adjust y-coordinates based on level\n",
    "        for node in pos:\n",
    "            level = self.G.nodes[node][\"level\"]\n",
    "            pos[node] = (pos[node][0], 1 - (level - 1) / 2)\n",
    "\n",
    "        # Draw nodes with different colors per level\n",
    "        colors = [\"lightblue\", \"lightgreen\", \"lightpink\"]\n",
    "        for level in [1, 2, 3]:\n",
    "            nodes_in_level = [\n",
    "                node for node in self.G.nodes() if self.G.nodes[node][\"level\"] == level\n",
    "            ]\n",
    "            nx.draw_networkx_nodes(\n",
    "                self.G,\n",
    "                pos,\n",
    "                nodelist=nodes_in_level,\n",
    "                node_color=colors[level - 1],\n",
    "                node_size=2000,\n",
    "            )\n",
    "\n",
    "        # Draw edges\n",
    "        nx.draw_networkx_edges(self.G, pos)\n",
    "\n",
    "        # Draw labels\n",
    "        labels = {\n",
    "            node: f\"{node}\\n{self.G.nodes[node]['distribution']}\"\n",
    "            for node in self.G.nodes()\n",
    "        }\n",
    "        nx.draw_networkx_labels(self.G, pos, labels, font_size=8)\n",
    "\n",
    "        plt.title(\"Hierarchical Bayesian Network\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Create and visualize network\n",
    "hbn = HierarchicalBayesianNetwork()\n",
    "hbn.visualize()\n",
    "\n",
    "\n",
    "# Example of generating data from this model\n",
    "def generate_sample_data(n_samples=1000):\n",
    "    # Sample from hyperpriors\n",
    "    mu_pop = np.random.normal(0, 1)\n",
    "    sigma_pop = np.random.gamma(2, 1)\n",
    "\n",
    "    # Sample group parameters\n",
    "    group_mus = np.random.normal(mu_pop, sigma_pop, size=3)\n",
    "    group_sigmas = np.random.gamma(2, 1, size=3)\n",
    "\n",
    "    # Generate observations\n",
    "    data = []\n",
    "    for i in range(3):  # For each group\n",
    "        group_data = np.random.normal(group_mus[i], group_sigmas[i], size=n_samples)\n",
    "        data.append(group_data)\n",
    "\n",
    "    return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allennlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
